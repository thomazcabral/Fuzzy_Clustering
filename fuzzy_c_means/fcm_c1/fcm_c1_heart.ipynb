{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X-5_kzR-_0cO"
   },
   "source": [
    "## Tratamento dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VnzujkKg_6xC"
   },
   "source": [
    "### Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "v9xQo6eL_vTW"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.metrics import adjusted_mutual_info_score\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "97ZB6HLiABGf"
   },
   "source": [
    "### Importando o dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "HAoOUquR_vTX",
    "outputId": "e23a4b05-d9d3-43b4-95a2-9e8bf1fe7422"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>num</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>160</td>\n",
       "      <td>286</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>108</td>\n",
       "      <td>1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>120</td>\n",
       "      <td>229</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   1       145   233    1        2      150      0      2.3      3   \n",
       "1   67    1   4       160   286    0        2      108      1      1.5      2   \n",
       "2   67    1   4       120   229    0        2      129      1      2.6      2   \n",
       "3   37    1   3       130   250    0        0      187      0      3.5      3   \n",
       "4   41    0   2       130   204    0        2      172      0      1.4      1   \n",
       "\n",
       "    ca  thal  num  \n",
       "0  0.0   6.0    0  \n",
       "1  3.0   3.0    2  \n",
       "2  2.0   7.0    1  \n",
       "3  0.0   3.0    0  \n",
       "4  0.0   3.0    0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/thomazaraujo/Documents/CIn-UFPE/PIBIC/Fuzzy_Clustering/datasets/heart.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 382
    },
    "id": "lEgGq8A7_vTZ",
    "outputId": "e0c7a61a-62ff-45f4-827d-db6300c88a2a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores ausentes após remoção:\n",
      "age         0\n",
      "sex         0\n",
      "cp          0\n",
      "trestbps    0\n",
      "chol        0\n",
      "fbs         0\n",
      "restecg     0\n",
      "thalach     0\n",
      "exang       0\n",
      "oldpeak     0\n",
      "slope       0\n",
      "ca          0\n",
      "thal        0\n",
      "num         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# remover linhas com valores ausentes\n",
    "df = df.dropna()\n",
    "# checar valores ausentes novamente\n",
    "missing_values = df.isnull().sum()\n",
    "print(\"Valores ausentes após remoção:\")\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DVYRw-XH_vTa",
    "outputId": "e61929f6-2864-4fde-81c7-d9fd138ffe8a"
   },
   "outputs": [],
   "source": [
    "labels = df[\"num\"].values\n",
    "df.drop(\"num\", axis=1, inplace=True)\n",
    "dados = df.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "ioHrpg_i_vTa",
    "outputId": "ca563ef4-160d-42b8-8145-389bf127b198"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1, 0, 0, 0, 3, 0, 2, 1, 0, 0, 2, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 3, 4, 0, 0, 0, 0, 3, 0, 2, 1, 0, 0, 0, 3, 1, 3, 0, 4, 0, 0, 0,\n",
       "       1, 4, 0, 4, 0, 0, 0, 0, 2, 0, 1, 1, 1, 1, 0, 0, 2, 0, 1, 0, 2, 2,\n",
       "       1, 0, 2, 1, 0, 3, 1, 1, 1, 0, 1, 0, 0, 3, 0, 0, 0, 3, 0, 0, 0, 0,\n",
       "       0, 0, 3, 0, 0, 0, 1, 2, 3, 0, 0, 0, 0, 0, 0, 3, 0, 2, 1, 2, 3, 1,\n",
       "       1, 0, 2, 2, 0, 0, 0, 3, 2, 3, 4, 0, 3, 1, 0, 3, 3, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 4, 3, 1, 0, 0, 1, 0, 1, 0, 1, 4, 0, 0, 0, 0, 0, 0, 4, 3,\n",
       "       1, 1, 1, 2, 0, 0, 4, 0, 0, 0, 0, 0, 1, 0, 3, 0, 1, 0, 4, 1, 0, 1,\n",
       "       0, 0, 3, 2, 0, 0, 1, 0, 0, 2, 1, 2, 0, 3, 2, 0, 3, 0, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 3, 3, 3, 0, 1, 0, 4, 0, 3, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       3, 1, 0, 0, 0, 3, 2, 0, 2, 1, 0, 0, 3, 2, 1, 0, 0, 0, 0, 0, 2, 0,\n",
       "       2, 2, 1, 3, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 3, 0, 0, 4, 2, 2,\n",
       "       1, 0, 1, 0, 2, 0, 1, 0, 0, 0, 1, 0, 2, 0, 3, 0, 2, 4, 2, 0, 0, 1,\n",
       "       0, 2, 2, 1, 0, 3, 1, 1, 2, 3, 1])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d5iBHEpvAmkq"
   },
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7eqKU05YAn_b"
   },
   "source": [
    "### Inicialização da matriz de pertinência"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xgjmQE_OAp21"
   },
   "source": [
    "A matriz de pertinência é inicializada aleatoriamente $u_{ik}(i=1,...c$ e $k=1,...,n)$ do objeto $k$ pertencente ao grupo $C_i$ tal que:\n",
    "- $u_{ik} \\in [0,1]$;\n",
    "- $0 < \\sum_{k=1}^nu_{ik} < n$;\n",
    "- $\\sum_{i=1}^cu_{ik} = 1$ para todo $k \\in \\Omega$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "-wfMM6QjAr71"
   },
   "outputs": [],
   "source": [
    "def inicializacao_matriz_pertinencia(num_amostras, num_clusters):\n",
    "    matriz_pertinencia = np.random.rand(num_amostras, num_clusters) # gera uma matriz inicial aleatória com valores entre 0 e 1\n",
    "    matriz_pertinencia = matriz_pertinencia / matriz_pertinencia.sum(axis=1, keepdims=True) # normalização da matriz pra garantir que a soma dos graus dê um\n",
    "    return matriz_pertinencia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicialização dos pesos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O peso é inicializado de maneira fixa $\\alpha_{ij}$, que determina a influência da variável $j$ para o grupo $i$ seguindo a única restrição seguinte:\n",
    "- $\\alpha_{ij}=1,\\forall i, j$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inicializacao_pesos(num_clusters, num_variaveis):\n",
    "    pesos = np.ones((num_clusters, num_variaveis)) # inicializa os pesos com 1\n",
    "    return pesos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pzZVWXpcAw61"
   },
   "source": [
    "### Atualização dos centroides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q-7TBwkIAy2H"
   },
   "source": [
    "Fixo os graus de pertinência, os centroides são atualizados com base nessa equação:\n",
    "\n",
    "### $y_i = \\frac{\\sum_{k=1}^n(u_{ik})^mx_k}{\\sum_{k=1}^n(u_{ik})^m}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "5UEHGtMMA7bD"
   },
   "outputs": [],
   "source": [
    "def atualizacao_centroides(dados, matriz_pertinencia, m):\n",
    "    matriz_pertinencia_m = matriz_pertinencia ** m # preparação dos graus de pertinência\n",
    "    centroides = np.dot(matriz_pertinencia_m.T, dados) / np.sum(matriz_pertinencia_m.T, axis=1, keepdims=True) # fórmula para o cálculo dos centroides\n",
    "    return centroides"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iwNFRpw_A81-"
   },
   "source": [
    "### Atualização da matriz de pertinência"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E-kg2pxRA9Te"
   },
   "source": [
    "Fixo o protótipo, os graus de pertinência são atualizados com base nessa equação:\n",
    "\n",
    "### $u_{ik} = [\\sum_{h=1}^c\\{\\frac{d(x_k,y_i)}{d(x_k,y_h)}\\}^\\frac{1}{m-1}]^{-1}$\n",
    "\n",
    "onde\n",
    "\n",
    "$d_{ik}=\\sum_{j=1}^p(\\alpha_{ij})^t(x_{jk}-y_{ij})^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcula_distancia(dados, centroides, pesos, t):\n",
    "    diff_sq = (dados[:, np.newaxis, :] - centroides) ** 2\n",
    "    pesos_t = pesos ** t\n",
    "    \n",
    "    weighted_diff_sq = pesos_t * diff_sq\n",
    "    matriz_distancias = np.sum(weighted_diff_sq, axis=2)\n",
    "    matriz_distancias = np.fmax(matriz_distancias, np.finfo(np.float64).eps)\n",
    "    return matriz_distancias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "e75eiSY2BAeI"
   },
   "outputs": [],
   "source": [
    "def atualizacao_matriz_pertinencia(dados, centroides, pesos, m, t):\n",
    "    matriz_distancias = calcula_distancia(dados, centroides, pesos, t)\n",
    "    matriz_distancias_inversa = 1 / matriz_distancias\n",
    "    potencia = 1 / (m-1)\n",
    "    matriz_pertinencia_atualizada = matriz_distancias_inversa ** potencia / np.sum(matriz_distancias_inversa ** potencia, axis=1, keepdims=True) # fórmula para atualizar os graus de pertinência\n",
    "    return matriz_pertinencia_atualizada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Atualização dos pesos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fixo o protótipo e o grau de pertinência, atualize os pesos com base na seguinte equação:\n",
    "\n",
    "### $\\alpha_{ij}=[\\sum_{r=1}^p(\\frac{\\sum_{k=1}^n(u_{ik})^m(x_{jk}-y_{ij})^2}{\\sum_{k=1}^n(u_{ik})^m(x_{rk}-y_{ir})^2})^\\frac{1}{t-1}]^{-1}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def atualizacao_pesos(dados, centroides, matriz_pertinencia, m, t):\n",
    "    num_amostras, num_variaveis = dados.shape\n",
    "    num_clusters = centroides.shape[0]\n",
    "\n",
    "    matriz_pertinencia_m = matriz_pertinencia ** m\n",
    "    diff_sq = (dados[:, np.newaxis, :] - centroides) ** 2\n",
    "    weighted_diff_sq = matriz_pertinencia_m[:, :, np.newaxis] * diff_sq\n",
    "\n",
    "    D = np.sum(weighted_diff_sq, axis=0)\n",
    "    D = np.fmax(D, np.finfo(np.float64).eps)\n",
    "\n",
    "    pesos = np.zeros((num_clusters, num_variaveis))\n",
    "    \n",
    "    potencia = 1.0 / (t - 1)\n",
    "    razao = D[:, :, np.newaxis] / D[:, np.newaxis, :]\n",
    "    razao_potencia = razao ** potencia\n",
    "    soma_termos = np.sum(razao_potencia, axis=2)\n",
    "    pesos = 1.0 / soma_termos\n",
    "     \n",
    "    return pesos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GN4qqayDBCfP"
   },
   "source": [
    "### FCM-C¹"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ES1PPCEYBDsv"
   },
   "source": [
    "Ações:\n",
    "1. Inicialização da matriz de pertinência\n",
    "2. Atualização dos centroides\n",
    "3. Atualização da matriz de pertinência\n",
    "4. Atualização dos pesos\n",
    "\n",
    "Critérios de parada:\n",
    "1. Número máximo de iterações atingido\n",
    "2. Pouca diferença (erro) entre as matrizes de pertinência de iterações consecutivas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "LGX-CxDmBF4l"
   },
   "outputs": [],
   "source": [
    "def fcm(dados, num_clusters, m=2, t=2, max_iter=10**6, erro=1e-9):\n",
    "    num_amostras, num_variaveis = dados.shape\n",
    "    matriz_pertinencia = inicializacao_matriz_pertinencia(num_amostras, num_clusters)\n",
    "    pesos = inicializacao_pesos(num_clusters, num_variaveis)\n",
    "    for _ in range(max_iter): # primeiro critério de parada\n",
    "        centroides = atualizacao_centroides(dados, matriz_pertinencia, m)\n",
    "        nova_matriz_pertinencia = atualizacao_matriz_pertinencia(dados, centroides, pesos, m, t)\n",
    "        pesos = atualizacao_pesos(dados, centroides, nova_matriz_pertinencia, m, t)\n",
    "        if np.linalg.norm(nova_matriz_pertinencia - matriz_pertinencia) < erro: # segundo critério de parada\n",
    "            break\n",
    "        matriz_pertinencia = nova_matriz_pertinencia\n",
    "    return centroides, matriz_pertinencia, pesos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0L2ILGCdBKAr"
   },
   "source": [
    "### Índice de Rand Ajustado (IRA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "yupjY7ZoBNpL"
   },
   "outputs": [],
   "source": [
    "def indice_rand(labels, predicted_labels):\n",
    "    return adjusted_rand_score(labels, predicted_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NwsraaD_BOYI"
   },
   "source": [
    "### Simulação de Monte Carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "iunOfj51_vTb"
   },
   "outputs": [],
   "source": [
    "def simulacao_monte_carlo(dados, labels, num_clusters, num_trials):\n",
    "    ari = []\n",
    "    ami = []\n",
    "    for _ in range(num_trials):\n",
    "        centroides, matriz_pertinencia, pesos = fcm(dados, num_clusters)\n",
    "        predicted_labels = np.argmax(matriz_pertinencia, axis=1)\n",
    "        #print(pesos)\n",
    "        idx_rand = indice_rand(labels, predicted_labels)\n",
    "        ari.append(idx_rand)\n",
    "        ami_rand = adjusted_mutual_info_score(labels, predicted_labels)\n",
    "        ami.append(ami_rand)\n",
    "    mean_ari = np.mean(ari)\n",
    "    std_ari = np.std(ari)\n",
    "    mean_ami = np.mean(ami)\n",
    "    std_ami = np.std(ami)\n",
    "    return mean_ari, std_ari, mean_ami, std_ami"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7njVCaopBW1L"
   },
   "source": [
    "### Definição de parâmetros e execução do método"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bwMeGgYu_vTb",
    "outputId": "14ebb19e-2c9e-4cc9-fa5e-53eda3416024"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monte Carlo FCM-C¹ Clustering Results (100 trials)\n",
      "Mean Rand Index: 0.0131\n",
      "Standard Deviation of Rand Index: 0.0320\n",
      "\n",
      "Mean Adjusted Mutual Information: 0.0112\n",
      "Standard Deviation of Adjusted Mutual Information: 0.0140\n"
     ]
    }
   ],
   "source": [
    "num_clusters = 5\n",
    "num_trials = 100\n",
    "mean_ari, std_ari, mean_ami, std_ami = simulacao_monte_carlo(dados, labels, num_clusters, num_trials)\n",
    "\n",
    "print(f\"Monte Carlo FCM-C¹ Clustering Results ({num_trials} trials)\")\n",
    "print(f\"Mean Rand Index: {mean_ari:.4f}\")\n",
    "print(f\"Standard Deviation of Rand Index: {std_ari:.4f}\")\n",
    "print(\"\")\n",
    "print(f\"Mean Adjusted Mutual Information: {mean_ami:.4f}\")\n",
    "print(f\"Standard Deviation of Adjusted Mutual Information: {std_ami:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
