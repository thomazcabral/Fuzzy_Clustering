{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Fuzzy C-medoids method: Implementation\n",
    "\n",
    "## Equations\n",
    "\n",
    "### $J= \\sum_{i=1}^{c} \\sum_{k=1}^{n} \\sum_{j=1}^{p} \\left(u_{ijk} \\right)^{m} d_{ijk}$ - Objective function to minimize.\n",
    "\n",
    "### $d_{ijk} = \\left(x_{jk} - y_{ij} \\right)^{2}$ - euclidian distance squared.\n",
    "\n",
    "### $q = \\argmin_{1 \\le i \\le c} \\sum_{j=1}^p \\sum_{k=1}^n (u_{ijk})^m \\cdot d_{ijk}$ - prototype coordinate of a given cluster in feature j.\n",
    "\n",
    "### $ u_{ijk} =  \\left[\\sum_{h=1}^{c}\\sum_{l=1}^{p} \\left(\\frac{d_{ijk}}{d_{hlk}}\\right)^{(1/(m-1))}  \\right]^{-1} $ - membership degree of pattern k in cluster $C_{i}$ on the feature j.\n",
    "\n",
    "### $\\delta_{ik} = \\sum_{j=1}^{p} u_{ijk}$ - represents an aggregation measure for all the p features.\n",
    "\n",
    "## Constraints:\n",
    "\n",
    "### - $u_{ijk} \\in [0, 1]$ for all i, j and k;\n",
    "### - $0 < \\sum_{j=1}^{p} \\sum_{k=1}^{n} u_{ijk} < n$ for all i and\n",
    "### - $\\sum_{i=1}^{c}\\sum_{j=1}^{p}u_{ijk} = 1$ for all k."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/rd/2w0dpjn11nz05hr2v2bp3zy80000gn/T/ipykernel_2174/895862619.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"Class\"].replace({1: 0, 2: 1, 3: 2}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/thomazaraujo/Documents/CIn-UFPE/PIBIC/datasets/wine.csv')\n",
    "df = df.rename(columns={'Wine': 'Class'})\n",
    "df[\"Class\"].replace({1: 0, 2: 1, 3: 2}, inplace=True)\n",
    "labels = df[\"Class\"].values\n",
    "df.drop(\"Class\", axis=1, inplace=True)\n",
    "dados = df.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Método de agrupamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MFCMedoids:\n",
    "    def __init__(self, c, X, m):\n",
    "        self.c = c\n",
    "        self.n = X.shape[0]\n",
    "        self.p = X.shape[1]\n",
    "        self.m = m\n",
    "        self.epsilon = 1e-10  # To prevent division by zero\n",
    "\n",
    "    def initialize_u(self):\n",
    "        return np.random.dirichlet(alpha=np.ones(self.c * self.p),\n",
    "                                   size=self.n).reshape(self.n, self.c, self.p)\n",
    "\n",
    "    def find_medoids(self, X, U):\n",
    "        medoids = np.zeros((self.c, self.p))\n",
    "        U_m = U ** self.m  # (n, c, p)\n",
    "\n",
    "        # Para cada possível q (0 <= q < n), criamos um tensor de distâncias quadradas para todos os outros k e p\n",
    "        # (n, n, p) -> distances_squared[k, q, j] = (X[k, j] - X[q, j]) ** 2\n",
    "        distances_squared = (X[:, np.newaxis, :] - X[np.newaxis, :, :]) ** 2  # shape (n, n, p)\n",
    "\n",
    "        for i in range(self.c):\n",
    "            # Para o cluster i, obtemos U_m[:, i, :] -> shape (n, p)\n",
    "            # Queremos calcular o custo de cada q ser o medoide: somatório sobre j e k de u_m[k, i, j] * d(k, q, j)\n",
    "            \n",
    "            # Expand u_m para fazer broadcast: (n, 1, p) para multiplicar com (n, n, p)\n",
    "            u_m_expanded = U_m[:, i, :][:, np.newaxis, :]  # shape (n, 1, p)\n",
    "\n",
    "            # Custo total para cada q: soma sobre k e j\n",
    "            cost_per_q = np.sum(u_m_expanded * distances_squared, axis=(0, 2))  # shape (n,)\n",
    "\n",
    "            best_q = np.argmin(cost_per_q)\n",
    "            medoids[i] = X[best_q]\n",
    "\n",
    "        return medoids\n",
    "\n",
    "\n",
    "    def get_distances(self, X, medoids):\n",
    "        return (X[:, np.newaxis, :] - medoids[np.newaxis, :, :]) ** 2\n",
    "\n",
    "    def update_u(self, D):\n",
    "        D = np.maximum(D, self.epsilon)  # Avoid division by zero\n",
    "        ratio = (D[:, np.newaxis, np.newaxis, :, :] / D[:, :, :, np.newaxis, np.newaxis]) ** (1 / (self.m - 1))\n",
    "        return 1 / np.sum(ratio, axis=(3, 4))\n",
    "\n",
    "    def get_objective_function(self, U, D):\n",
    "        return np.sum((U ** self.m) * D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfcm_run(dados, num_clusters, m=2, max_iter=1000, epsilon=1e-5):\n",
    "    mfcm = MFCMedoids(c=num_clusters, X=dados, m=m)  # Create the MFCMedoids object\n",
    "\n",
    "    U = mfcm.initialize_u()  # Initialize the membership matrix\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        medoids = mfcm.find_medoids(dados, U)\n",
    "        D = mfcm.get_distances(dados, medoids)\n",
    "        new_U = mfcm.update_u(D)\n",
    "        \n",
    "        # Check for convergence\n",
    "        if np.linalg.norm(U - new_U) < epsilon:\n",
    "            break\n",
    "        \n",
    "        U = new_U\n",
    "\n",
    "    Delta = np.sum(U, axis=2)  # Summing over the second axis (variables j)\n",
    "\n",
    "    return medoids, U, Delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulação de Monte Carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo_simulation(dados, labels, num_clusters, num_trials):\n",
    "    results = []\n",
    "    for _ in range(num_trials):\n",
    "        medoids, U, Delta = mfcm_run(dados, num_clusters)\n",
    "        predicted_labels = np.argmax(Delta, axis=1)\n",
    "        ari = adjusted_rand_score(labels, predicted_labels)\n",
    "        if ari > 0.1:\n",
    "            results.append(ari)\n",
    "    mean_rand_index = np.mean(results)\n",
    "    std_rand_index = np.std(results)\n",
    "    return mean_rand_index, std_rand_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean ARI: 0.3835078817761286\n",
      "Std ARI: 0.012103664921134964\n"
     ]
    }
   ],
   "source": [
    "num_clusters = 3\n",
    "num_trials = 100\n",
    "mean_rand_index, std_rand_index = monte_carlo_simulation(dados, labels, num_clusters, num_trials)\n",
    "\n",
    "print(f\"Mean ARI: {mean_rand_index}\")\n",
    "print(f\"Std ARI: {std_rand_index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Medidas de Dispersão Bruta Totais ---\n",
      "  T (Dispersão Total): 1.0615\n",
      "  B (Dispersão Inter-grupo): 1.2806\n",
      "  J (Dispersão Intra-grupo): 2.3006\n",
      "\n",
      "--- 2. Medidas de Dispersão Bruta por Grupo (Ti, Bi, Ji) ---\n",
      "               Ti        Bi        Ji\n",
      "Grupo_1  0.342022  0.227665  0.747575\n",
      "Grupo_2  0.361150  0.371040  0.719398\n",
      "Grupo_3  0.358298  0.681888  0.833649\n",
      "\n",
      "--- 3. Medidas de Dispersão Bruta por Variável (Tj, Bj, Jj) ---\n",
      "             Tj        Bj        Jj\n",
      "Var_1  0.302573  0.320328  0.635323\n",
      "Var_2  0.256801  0.404761  0.596191\n",
      "Var_3  0.247669  0.026000  0.306337\n",
      "Var_4  0.254428  0.529505  0.762771\n",
      "\n",
      "--- 4. Medida de Dispersão Bruta T_ij ---\n",
      "        Grupo_1   Grupo_2   Grupo_3\n",
      "Var_1  0.115622  0.083683  0.103268\n",
      "Var_2  0.078681  0.080528  0.097592\n",
      "Var_3  0.063236  0.105783  0.078651\n",
      "Var_4  0.084483  0.091157  0.078787\n",
      "\n",
      "--- 5. Medida de Dispersão Bruta B_ij ---\n",
      "        Grupo_1   Grupo_2   Grupo_3\n",
      "Var_1  0.084352  0.003569  0.232407\n",
      "Var_2  0.060502  0.055047  0.289212\n",
      "Var_3  0.001600  0.005286  0.019114\n",
      "Var_4  0.081211  0.307139  0.141155\n",
      "\n",
      "--- 6. Medida de Dispersão Bruta J_ij ---\n",
      "        Grupo_1   Grupo_2   Grupo_3\n",
      "Var_1  0.278599  0.099915  0.256809\n",
      "Var_2  0.193626  0.196716  0.205849\n",
      "Var_3  0.064419  0.120506  0.121411\n",
      "Var_4  0.210931  0.302261  0.249579\n",
      "\n",
      "\n",
      "==================================================\n",
      "             ÍNDICES DE INTERPRETAÇÃO FINAIS\n",
      "==================================================\n",
      "\n",
      "--- 7. Índices Globais ---\n",
      "  R (Heterogeneidade Global): 1.2064\n",
      "\n",
      "--- 8. Índices por Variável (CORj, CTRj) ---\n",
      "         COR(j)    CTR(j)\n",
      "Var_1  1.058679  0.250140\n",
      "Var_2  1.576165  0.316073\n",
      "Var_3  0.104980  0.020303\n",
      "Var_4  2.081161  0.413484\n",
      "\n",
      "--- 9. Índices de Contribuição Relativa por Grupo (T(i), B(i), J(i)) ---\n",
      "             T(i)      J(i)      B(i)\n",
      "Grupo_1  0.322216  0.324945  0.177781\n",
      "Grupo_2  0.340236  0.312697  0.289741\n",
      "Grupo_3  0.337549  0.362358  0.532478\n",
      "\n",
      "--- 10. Índice COR(i,j) ---\n",
      "        Grupo_1   Grupo_2   Grupo_3\n",
      "Var_1  0.278782  0.011794  0.768103\n",
      "Var_2  0.235601  0.214355  1.126209\n",
      "Var_3  0.006460  0.021343  0.077177\n",
      "Var_4  0.319190  1.207176  0.554795\n",
      "\n",
      "--- 11. Índice CTR(i,j) ---\n",
      "        Grupo_1   Grupo_2   Grupo_3\n",
      "Var_1  0.370509  0.009618  0.340829\n",
      "Var_2  0.265752  0.148358  0.424133\n",
      "Var_3  0.007028  0.014246  0.028031\n",
      "Var_4  0.356711  0.827778  0.207006\n",
      "\n",
      "--- 12. Índice CE(i,j) ---\n",
      "        Grupo_1   Grupo_2   Grupo_3\n",
      "Var_1  0.065869  0.002787  0.181484\n",
      "Var_2  0.047246  0.042985  0.225842\n",
      "Var_3  0.001249  0.004128  0.014926\n",
      "Var_4  0.063416  0.239841  0.110226\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def medoide_global_calc(dados, u_ijk, m=2):\n",
    "    n_objetos, p_variaveis = dados.shape\n",
    "    \n",
    "    u_ijk_m = u_ijk ** m # já eleva os graus de pertinência m\n",
    "    pesos_kj = np.sum(u_ijk_m, axis=0).T \n",
    "\n",
    "    min_dissimilarity = np.inf\n",
    "    medoid_index = -1\n",
    "\n",
    "    for q in range(n_objetos): # testa cada ponto como candidato a medoide\n",
    "        candidato_q = dados[q, :]\n",
    "        distancias_sq = (dados - candidato_q) ** 2 # distância dos pontos ao candidato\n",
    "        dissimilaridade_total_q = np.sum(pesos_kj * distancias_sq)\n",
    "        \n",
    "        if dissimilaridade_total_q < min_dissimilarity: # se o candidato for melhor\n",
    "            min_dissimilarity = dissimilaridade_total_q\n",
    "            medoid_index = q\n",
    "            \n",
    "    medoide_global = dados[medoid_index, :]\n",
    "    return medoide_global\n",
    "\n",
    "def indices(dados, prototipos, u_ijk, m=2):\n",
    "    n, p = dados.shape\n",
    "    c, _, _ = u_ijk.shape\n",
    "\n",
    "    u_ijk_m = u_ijk ** m\n",
    "    \n",
    "    grupo_nomes = [f'Grupo_{i+1}' for i in range(c)] # grupo1, grupo2, ... para output\n",
    "    variavel_nomes = [f'Var_{j+1}' for j in range(p)] # var1, var2, ... para output\n",
    "\n",
    "    z = medoide_global_calc(dados, u_ijk, m)\n",
    "\n",
    "    # dispersão intra-grupo (J)\n",
    "    dist_intra = (dados.T.reshape(1, p, n) - prototipos.reshape(c, p, 1)) ** 2\n",
    "    J_ijk = u_ijk_m * dist_intra\n",
    "    J = np.sum(J_ijk)\n",
    "    J_por_grupo = np.sum(J_ijk, axis=(1, 2)) # Ji\n",
    "    J_por_variavel = np.sum(J_ijk, axis=(0, 2)) # Jj\n",
    "    J_ij = np.sum(J_ijk, axis=2)               \n",
    "\n",
    "    # dispersão inter-grupo (B)\n",
    "    dist_inter = (prototipos - z) ** 2\n",
    "    B_ijk = u_ijk_m * dist_inter.reshape(c, p, 1)\n",
    "    B = np.sum(B_ijk)\n",
    "    B_por_variavel = np.sum(B_ijk, axis=(0, 2)) # Bj\n",
    "    B_por_grupo = np.sum(B_ijk, axis=(1, 2)) # Bi\n",
    "    B_ij = np.sum(B_ijk, axis=2)\n",
    "\n",
    "    # dispersão total (T)\n",
    "    dist_total = (dados - z) ** 2\n",
    "    dist_total_bcast = dist_total.T.reshape(1, p, n)\n",
    "    T_ijk = u_ijk_m * dist_total_bcast\n",
    "    T = np.sum(T_ijk)\n",
    "    T_por_variavel = np.sum(T_ijk, axis=(0, 2)) # Tj\n",
    "    T_por_grupo = np.sum(T_ijk, axis=(1, 2)) # Ti\n",
    "    T_ij = np.sum(T_ijk, axis=2)\n",
    "\n",
    "    # índices globais por variável\n",
    "    R_global = B / T\n",
    "    COR_j = np.divide(B_por_variavel, T_por_variavel, out=np.zeros_like(B_por_variavel), where=T_por_variavel!=0)\n",
    "    CTR_j = np.divide(B_por_variavel, B, out=np.zeros_like(B_por_variavel), where=B!=0)\n",
    "    df_indices_variavel = pd.DataFrame({'COR(j)': COR_j, 'CTR(j)': CTR_j}, index=variavel_nomes)\n",
    "\n",
    "    # índices de contribuição relativa por grupo\n",
    "    T_i_rel = np.divide(T_por_grupo, T, out=np.zeros_like(T_por_grupo), where=T!=0)\n",
    "    J_i_rel = np.divide(J_por_grupo, J, out=np.zeros_like(J_por_grupo), where=J!=0)\n",
    "    B_i_rel = np.divide(B_por_grupo, B, out=np.zeros_like(B_por_grupo), where=B!=0)\n",
    "    df_indices_grupo = pd.DataFrame({'T(i)': T_i_rel, 'J(i)': J_i_rel, 'B(i)': B_i_rel}, index=grupo_nomes)\n",
    "\n",
    "    # índices por grupo e variável\n",
    "    COR_ij = np.divide(B_ij, T_por_variavel, out=np.zeros_like(B_ij), where=T_por_variavel!=0)\n",
    "    df_cor_ij = pd.DataFrame(COR_ij.T, index=variavel_nomes, columns=grupo_nomes)\n",
    "    \n",
    "    CTR_ij = np.divide(B_ij, B_por_grupo.reshape(-1, 1), out=np.zeros_like(B_ij), where=B_por_grupo.reshape(-1, 1)!=0)\n",
    "    df_ctr_ij = pd.DataFrame(CTR_ij.T, index=variavel_nomes, columns=grupo_nomes)\n",
    "    \n",
    "    CE_ij = np.divide(B_ij, B, out=np.zeros_like(B_ij), where=B!=0)\n",
    "    df_ce_ij = pd.DataFrame(CE_ij.T, index=variavel_nomes, columns=grupo_nomes)\n",
    "\n",
    "    resultados = {\n",
    "        'T_total_bruto': T,\n",
    "        'B_total_bruto': B,\n",
    "        'J_total_bruto': J,\n",
    "        'dispersao_bruta_por_grupo': pd.DataFrame({'Ti': T_por_grupo, 'Bi': B_por_grupo, 'Ji': J_por_grupo}, index=grupo_nomes),\n",
    "        'dispersao_bruta_por_variavel': pd.DataFrame({'Tj': T_por_variavel, 'Bj': B_por_variavel, 'Jj': J_por_variavel}, index=variavel_nomes),\n",
    "        'T_ij_bruto': pd.DataFrame(T_ij.T, index=variavel_nomes, columns=grupo_nomes),\n",
    "        'B_ij_bruto': pd.DataFrame(B_ij.T, index=variavel_nomes, columns=grupo_nomes),\n",
    "        'J_ij_bruto': pd.DataFrame(J_ij.T, index=variavel_nomes, columns=grupo_nomes),\n",
    "        'R_global': R_global,\n",
    "        'indices_por_variavel': df_indices_variavel,\n",
    "        'indices_por_grupo': df_indices_grupo,\n",
    "        'COR(i,j)': df_cor_ij,\n",
    "        'CTR(i,j)': df_ctr_ij,\n",
    "        'CE(i,j)': df_ce_ij\n",
    "    }\n",
    "    \n",
    "    return resultados\n",
    "\n",
    "\n",
    "np.random.seed(42)\n",
    "# dummy data\n",
    "n_objetos, p_variaveis, c_grupos = 100, 4, 3\n",
    "dados_exemplo = np.random.rand(n_objetos, p_variaveis)\n",
    "prototipos_exemplo = np.random.rand(c_grupos, p_variaveis)\n",
    "u_ijk_exemplo = np.random.rand(c_grupos, p_variaveis, n_objetos)\n",
    "u_ijk_exemplo /= np.sum(u_ijk_exemplo, axis=(0, 1))\n",
    "\n",
    "indices = indices(dados_exemplo, prototipos_exemplo, u_ijk_exemplo)\n",
    "\n",
    "# Resultados\n",
    "print(\"--- 1. Medidas de Dispersão Bruta Totais ---\")\n",
    "print(f\"  T (Dispersão Total): {indices['T_total_bruto']:.4f}\")\n",
    "print(f\"  B (Dispersão Inter-grupo): {indices['B_total_bruto']:.4f}\")\n",
    "print(f\"  J (Dispersão Intra-grupo): {indices['J_total_bruto']:.4f}\\n\")\n",
    "\n",
    "print(\"--- 2. Medidas de Dispersão Bruta por Grupo (Ti, Bi, Ji) ---\")\n",
    "print(indices['dispersao_bruta_por_grupo'])\n",
    "\n",
    "print(\"\\n--- 3. Medidas de Dispersão Bruta por Variável (Tj, Bj, Jj) ---\")\n",
    "print(indices['dispersao_bruta_por_variavel'])\n",
    "\n",
    "print(\"\\n--- 4. Medida de Dispersão Bruta T_ij ---\")\n",
    "print(indices['T_ij_bruto'])\n",
    "\n",
    "print(\"\\n--- 5. Medida de Dispersão Bruta B_ij ---\")\n",
    "print(indices['B_ij_bruto'])\n",
    "\n",
    "print(\"\\n--- 6. Medida de Dispersão Bruta J_ij ---\")\n",
    "print(indices['J_ij_bruto'])\n",
    "\n",
    "print(\"\\n\\n\" + \"=\"*50)\n",
    "print(\"             ÍNDICES DE INTERPRETAÇÃO FINAIS\")\n",
    "print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "print(\"--- 7. Índices Globais ---\")\n",
    "print(f\"  R (Heterogeneidade Global): {indices['R_global']:.4f}\\n\")\n",
    "\n",
    "print(\"--- 8. Índices por Variável (CORj, CTRj) ---\")\n",
    "print(indices['indices_por_variavel'])\n",
    "\n",
    "print(\"\\n--- 9. Índices de Contribuição Relativa por Grupo (T(i), B(i), J(i)) ---\")\n",
    "print(indices['indices_por_grupo'])\n",
    "\n",
    "print(\"\\n--- 10. Índice COR(i,j) ---\")\n",
    "print(indices['COR(i,j)'])\n",
    "\n",
    "print(\"\\n--- 11. Índice CTR(i,j) ---\")\n",
    "print(indices['CTR(i,j)'])\n",
    "\n",
    "print(\"\\n--- 12. Índice CE(i,j) ---\")\n",
    "print(indices['CE(i,j)'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
