{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Fuzzy C-medoids method: Implementation\n",
    "\n",
    "## Equations\n",
    "\n",
    "### $J= \\sum_{i=1}^{c} \\sum_{k=1}^{n} \\sum_{j=1}^{p} \\left(u_{ijk} \\right)^{m} d_{ijk}$ - Objective function to minimize.\n",
    "\n",
    "### $d_{ijk} = \\left(x_{jk} - y_{ij} \\right)^{2}$ - euclidian distance squared.\n",
    "\n",
    "### $q = \\argmin_{1 \\le i \\le c} \\sum_{j=1}^p \\sum_{k=1}^n (u_{ijk})^m \\cdot d_{ijk}$ - prototype coordinate of a given cluster in feature j.\n",
    "\n",
    "### $ u_{ijk} =  \\left[\\sum_{h=1}^{c}\\sum_{l=1}^{p} \\left(\\frac{d_{ijk}}{d_{hlk}}\\right)^{(1/(m-1))}  \\right]^{-1} $ - membership degree of pattern k in cluster $C_{i}$ on the feature j.\n",
    "\n",
    "### $\\delta_{ik} = \\sum_{j=1}^{p} u_{ijk}$ - represents an aggregation measure for all the p features.\n",
    "\n",
    "## Constraints:\n",
    "\n",
    "### - $u_{ijk} \\in [0, 1]$ for all i, j and k;\n",
    "### - $0 < \\sum_{j=1}^{p} \\sum_{k=1}^{n} u_{ijk} < n$ for all i and\n",
    "### - $\\sum_{i=1}^{c}\\sum_{j=1}^{p}u_{ijk} = 1$ for all k."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import adjusted_rand_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_configuracao(mu_list, sigma_list, tamanhos, config_id):\n",
    "    dfs = []\n",
    "    for i, (mu, sigma2, n) in enumerate(zip(mu_list, sigma_list, tamanhos)):\n",
    "        Sigma = np.diag(sigma2)\n",
    "        data = np.random.multivariate_normal(mu, Sigma, n)\n",
    "        df = pd.DataFrame(data, columns=[\"x1\", \"x2\"])\n",
    "        df[\"class\"] = i + 1\n",
    "        dfs.append(df)\n",
    "    df_config = pd.concat(dfs, ignore_index=True)\n",
    "    df_config[\"config\"] = config_id\n",
    "    return df_config\n",
    "\n",
    "np.random.seed(42)  # reprodutibilidade\n",
    "\n",
    "# -------------------------------\n",
    "# Configuração 1\n",
    "mu_1 = [[5, 0], [15, 5], [18, 14]]\n",
    "sigma2_1 = [[81, 9], [9, 100], [25, 36]]\n",
    "n1 = [200, 100, 50]\n",
    "df1 = gerar_configuracao(mu_1, sigma2_1, n1, config_id=1)\n",
    "l1 = \"Classes elípticas de tamanhos diferentes\"\n",
    "\n",
    "# -------------------------------\n",
    "# Configuração 2\n",
    "mu_2 = [[0, 0], [30, 0], [12, 25]]\n",
    "sigma2_2 = [[100, 100], [49, 49], [16, 16]]\n",
    "n2 = [200, 100, 50]\n",
    "df2 = gerar_configuracao(mu_2, sigma2_2, n2, config_id=2)\n",
    "l2 = \"Classes esféricas de tamanhos diferentes\"\n",
    "\n",
    "# -------------------------------\n",
    "# Configuração 3\n",
    "mu_3 = [[0, 0], [15, 5], [15, -5]]\n",
    "sigma2_3 = [[100, 4], [100, 4], [100, 4]]\n",
    "n3 = [100, 100, 100]\n",
    "df3 = gerar_configuracao(mu_3, sigma2_3, n3, config_id=3)\n",
    "l3 = \"Classes elípticas de tamanhos iguais\"\n",
    "\n",
    "# -------------------------------\n",
    "# Configuração 4\n",
    "mu_4 = [[0, 0], [15, 0], [-15, 0]]\n",
    "sigma2_4 = [[16, 16], [16, 16], [16, 16]]\n",
    "n4 = [100, 100, 100]\n",
    "df4 = gerar_configuracao(mu_4, sigma2_4, n4, config_id=4)\n",
    "l4 = \"Classes elípticas de tamanhos iguais\"\n",
    "\n",
    "# -------------------------------\n",
    "# Configuração 5\n",
    "mu_5 = [[5, 0], [15, 5], [10, -7], [3, 15]]\n",
    "sigma2_5 = [[81, 9], [9, 100], [49, 16], [25, 25]]\n",
    "n5 = [50, 50, 50, 50]\n",
    "df5 = gerar_configuracao(mu_5, sigma2_5, n5, config_id=5)\n",
    "l5 = \"3 classes elípticas e 1 esférica\"\n",
    "\n",
    "# -------------------------------\n",
    "# Configuração 6\n",
    "mu_6 = [[5, 0], [15, 5], [12, -12], [7, 17]]\n",
    "sigma2_6 = [[81, 9], [9, 100], [16, 16], [25, 25]]\n",
    "n6 = [50, 50, 50, 50]\n",
    "df6 = gerar_configuracao(mu_6, sigma2_6, n6, config_id=6)\n",
    "l6 = \"2 classes elípticas e 2 esféricas\"\n",
    "\n",
    "# -------------------------------\n",
    "# Configuração 7\n",
    "mu_7 = [[0, 0], [18, 0], [-18, 0], [0, -12]]\n",
    "sigma2_7 = [[12, 12], [20, 20], [16, 16], [81, 20]]\n",
    "n7 = [50, 50, 50, 50]\n",
    "df7 = gerar_configuracao(mu_7, sigma2_7, n7, config_id=7)\n",
    "l7 = \"1 classe elíptica e 3 esféricas\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MFCMedoids:\n",
    "    def __init__(self, c, X, m):\n",
    "        self.c = c\n",
    "        self.n = X.shape[0]\n",
    "        self.p = X.shape[1]\n",
    "        self.m = m\n",
    "        self.epsilon = 1e-10  # To prevent division by zero\n",
    "\n",
    "    def initialize_u(self):\n",
    "        return np.random.dirichlet(alpha=np.ones(self.c * self.p),\n",
    "                                   size=self.n).reshape(self.n, self.c, self.p)\n",
    "\n",
    "    def find_medoids(self, X, U):\n",
    "        medoids = np.zeros((self.c, self.p))\n",
    "        U_m = U ** self.m  # (n, c, p)\n",
    "\n",
    "        # Para cada possível q (0 <= q < n), criamos um tensor de distâncias quadradas para todos os outros k e p\n",
    "        # (n, n, p) -> distances_squared[k, q, j] = (X[k, j] - X[q, j]) ** 2\n",
    "        distances_squared = np.abs(X[:, np.newaxis, :] - X[np.newaxis, :, :])  # city block\n",
    "\n",
    "        for i in range(self.c):\n",
    "            # Para o cluster i, obtemos U_m[:, i, :] -> shape (n, p)\n",
    "            # Queremos calcular o custo de cada q ser o medoide: somatório sobre j e k de u_m[k, i, j] * d(k, q, j)\n",
    "            \n",
    "            # Expand u_m para fazer broadcast: (n, 1, p) para multiplicar com (n, n, p)\n",
    "            u_m_expanded = U_m[:, i, :][:, np.newaxis, :]  # shape (n, 1, p)\n",
    "\n",
    "            # Custo total para cada q: soma sobre k e j\n",
    "            cost_per_q = np.sum(u_m_expanded * distances_squared, axis=(0, 2))  # shape (n,)\n",
    "\n",
    "            best_q = np.argmin(cost_per_q)\n",
    "            medoids[i] = X[best_q]\n",
    "\n",
    "        return medoids\n",
    "\n",
    "    def get_distances(self, X, medoids):\n",
    "        return np.abs(X[:, np.newaxis, :] - medoids[np.newaxis, :, :]) # city block\n",
    "\n",
    "    def update_u(self, D):\n",
    "        D = np.maximum(D, self.epsilon)  # Avoid division by zero\n",
    "        ratio = (D[:, np.newaxis, np.newaxis, :, :] / D[:, :, :, np.newaxis, np.newaxis]) ** (1 / (self.m - 1))\n",
    "        return 1 / np.sum(ratio, axis=(3, 4))\n",
    "\n",
    "    def get_objective_function(self, U, D):\n",
    "        return np.sum((U ** self.m) * D)\n",
    "\n",
    "def mfcm_run(dados, num_clusters, m=2, max_iter=1000, epsilon=1e-5):\n",
    "    mfcm = MFCMedoids(c=num_clusters, X=dados, m=m)  # Create the MFCMedoids object\n",
    "\n",
    "    U = mfcm.initialize_u()  # Initialize the membership matrix\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        medoids = mfcm.find_medoids(dados, U)\n",
    "        D = mfcm.get_distances(dados, medoids)\n",
    "        new_U = mfcm.update_u(D)\n",
    "        \n",
    "        # Check for convergence\n",
    "        if np.linalg.norm(U - new_U) < epsilon:\n",
    "            break\n",
    "        \n",
    "        U = new_U\n",
    "\n",
    "    Delta = np.sum(U, axis=2)  # Summing over the second axis (variables j)\n",
    "\n",
    "    return medoids, U, Delta\n",
    "\n",
    "def monte_carlo_simulation(dados, labels, num_clusters, num_trials):\n",
    "    results = []\n",
    "    for _ in range(num_trials):\n",
    "        print(_)\n",
    "        medoids, U, Delta = mfcm_run(dados, num_clusters)\n",
    "        predicted_labels = np.argmax(Delta, axis=1)\n",
    "        ari = adjusted_rand_score(labels, predicted_labels)\n",
    "        results.append(ari)\n",
    "    mean_rand_index = np.mean(results)\n",
    "    std_rand_index = np.std(results)\n",
    "    return mean_rand_index, std_rand_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1\n",
    "for df in [df1, df2, df3, df4, df5, df6, df7]:\n",
    "    if i == 5 or i == 6 or i == 7:\n",
    "        num_clusters = 4\n",
    "    else:\n",
    "        num_clusters = 3\n",
    "    df.drop(\"config\", axis=1, inplace=True)\n",
    "    if i == 5 or i == 6 or i == 7:\n",
    "        df[\"class\"].replace({1: 0, 2: 1, 3: 2, 4: 3}, inplace=True)\n",
    "    else: \n",
    "        df[\"class\"].replace({1: 0, 2: 1, 3: 2}, inplace=True)\n",
    "    labels = df[\"class\"].values\n",
    "    df.drop(\"class\", axis=1, inplace=True)\n",
    "    dados = df.to_numpy()\n",
    "    num_trials = 100\n",
    "    mean_rand_index, std_rand_index = monte_carlo_simulation(dados, labels, num_clusters, num_trials)\n",
    "\n",
    "    print(f\"Monte Carlo MFCMdd Clustering Results for Config {i}\")\n",
    "    print(f\"Mean Rand Index: {mean_rand_index:.4f}\")\n",
    "    print(f\"Standard Deviation of Rand Index: {std_rand_index:.4f}\")\n",
    "    print(\"\\n\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os centroides das três classes estão localizados próximos uns dos outros:\n",
    "$\\mu_1 = \\begin{bmatrix} 20 \\\\ 20 \\end{bmatrix},$\n",
    "$\\mu_2 = \\begin{bmatrix} 23 \\\\ 23 \\end{bmatrix},$\n",
    "$\\mu_3 = \\begin{bmatrix} 26 \\\\ 20 \\end{bmatrix}$\n",
    "\n",
    "As classes apresentam diferentes formas e orientações devido às suas matrizes de covariância:\n",
    "$\\Sigma_1 = \\begin{bmatrix} 10 & 9 \\\\ 9 & 10 \\end{bmatrix},$\n",
    "$\\Sigma_2 = \\begin{bmatrix} 10 & -9 \\\\ -9 & 10 \\end{bmatrix},$\n",
    "$\\Sigma_3 = \\begin{bmatrix} 12 & 0 \\\\ 0 & 1 \\end{bmatrix}$\n",
    "\n",
    "- $\\Sigma_1$ e $\\Sigma_2$ geram distribuições elípticas com inclinação forte nas diagonais principais e secundárias, respectivamente.\n",
    "- $\\Sigma_3$ resulta em uma distribuição fortemente alongada no eixo $x$.\n",
    "\n",
    "Cada classe possui $5\\%$ de outliers, gerados a partir dos mesmos centros e covariâncias, mas com deslocamentos adicionais direcionados para regiões distantes dos centros originais. Os deslocamentos aplicados foram:\n",
    "$\\Delta_1 = \\begin{bmatrix} -10 \\\\ 5 \\end{bmatrix},$\n",
    "$\\Delta_2 = \\begin{bmatrix} 10 \\\\ -10 \\end{bmatrix},$\n",
    "$\\Delta_3 = \\begin{bmatrix} 6 \\\\ 10 \\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def config1_outliers(frac_outlier):\n",
    "    np.random.seed(42)\n",
    "    n = 150\n",
    "\n",
    "    # Covariâncias exageradas para formas mais elípticas e inclinadas\n",
    "    covs = [\n",
    "        [[10, 9], [9, 10]],     # fortemente inclinado (diagonal)\n",
    "        [[10, -9], [-9, 10]],   # diagonal oposta\n",
    "        [[12, 0], [0, 1]]       # fortemente alongado no eixo x\n",
    "    ]\n",
    "\n",
    "    mus = [[20, 20], [23, 23], [26, 20]]  # centroides próximos!\n",
    "    deslocamentos_outliers = [[-10, 5], [10, -10], [6, 10]]\n",
    "\n",
    "    dados, rotulos, outlier_flags = [], [], []\n",
    "\n",
    "    for i, (mu, cov, desloc) in enumerate(zip(mus, covs, deslocamentos_outliers)):\n",
    "        classe = np.random.multivariate_normal(mu, cov, size=n)\n",
    "        n_outliers = int(n * frac_outlier)\n",
    "\n",
    "        for j, ponto in enumerate(classe):\n",
    "            if j < n_outliers:\n",
    "                outlier = ponto + desloc + np.random.normal(0, 1.8, size=2)\n",
    "                dados.append(outlier)\n",
    "                outlier_flags.append(1)\n",
    "            else:\n",
    "                dados.append(ponto)\n",
    "                outlier_flags.append(0)\n",
    "            rotulos.append(f'Classe {i+1}')\n",
    "\n",
    "    # Garante que tudo fique no primeiro quadrante\n",
    "    dados = np.array(dados)\n",
    "    dados -= np.min(dados, axis=0)\n",
    "    dados += 1\n",
    "\n",
    "    df = pd.DataFrame(dados, columns=[\"x1\", \"x2\"])\n",
    "    df[\"Classe\"] = rotulos\n",
    "    df[\"Outlier\"] = outlier_flags\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for frac_outlier in [0.05, 0.1, 0.15, 0.2, 0.25]:\n",
    "    df = config1_outliers(frac_outlier)\n",
    "    df.drop(\"Outlier\", axis=1, inplace=True)\n",
    "    df['Classe'].replace({'Classe 1': 0, 'Classe 2': 1, 'Classe 3': 2}, inplace=True)\n",
    "    labels = df[\"Classe\"].values\n",
    "    df.drop(\"Classe\", axis=1, inplace=True)\n",
    "    dados = df.to_numpy()\n",
    "    num_clusters = 3\n",
    "    num_trials = 100\n",
    "    media_indice_rand, dp_indice_rand = monte_carlo_simulation(dados, labels, num_clusters, num_trials)\n",
    "    print(\"Fracao de outliers:\", frac_outlier)\n",
    "    print(\"Média do Índice Rand:\", media_indice_rand)\n",
    "    print(\"Desvio Padrão do Índice Rand:\", dp_indice_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"Outlier\", axis=1, inplace=True)\n",
    "df['Classe'].replace({'Classe 1': 0, 'Classe 2': 1, 'Classe 3': 2}, inplace=True)\n",
    "labels = df[\"Classe\"].values\n",
    "df.drop(\"Classe\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados = df.to_numpy()\n",
    "num_clusters = 3\n",
    "num_trials = 100\n",
    "media_indice_rand, dp_indice_rand = monte_carlo_simulation(dados, labels, num_clusters, num_trials)\n",
    "print(\"Resultados de Monte Carlo para dados desafiadores (100 tentativas)\")\n",
    "print(\"Média do Índice Rand:\", media_indice_rand)\n",
    "print(\"Desvio Padrão do Índice Rand:\", dp_indice_rand)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
