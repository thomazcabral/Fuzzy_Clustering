{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "609b96ac",
   "metadata": {},
   "source": [
    "## Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d24bcb9352fbc662",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-23T22:47:35.174123Z",
     "start_time": "2024-07-23T22:47:33.507128Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import adjusted_rand_score, adjusted_mutual_info_score\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from ucimlrepo import fetch_ucirepo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614723f2",
   "metadata": {},
   "source": [
    "## Tratamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0615bda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = fetch_ucirepo(id=45)\n",
    "df = pd.DataFrame(dataset.data.features)\n",
    "if dataset.data.targets is not None:\n",
    "    # targets pode ser Series ou DataFrame dependendo do conjunto\n",
    "    targets = pd.DataFrame(dataset.data.targets)\n",
    "    df = pd.concat([df, targets], axis=1)\n",
    "\n",
    "df = df.dropna()\n",
    "labels = df[\"num\"].values\n",
    "df.drop(\"num\", axis=1, inplace=True)\n",
    "dados = df.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e68412",
   "metadata": {},
   "source": [
    "## Método de agrupamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "549c38ec38602e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MFCM():\n",
    "    def __init__(self, c, X, m):\n",
    "        self.c = c\n",
    "        self.n = X.shape[0]\n",
    "        self.p = X.shape[1]\n",
    "        self.m = m\n",
    "\n",
    "        ##\n",
    "        self.global_var = np.var(X, axis=0).mean() # pré-calcula a variância global dos dados para regularização\n",
    "\n",
    "    def initialize_u(self):\n",
    "        u_flat = np.random.dirichlet(alpha=np.ones(self.c * self.p), size=self.n)\n",
    "        return u_flat.reshape(self.n, self.c, self.p)\n",
    "    \n",
    "    def initialize_lambda(self):\n",
    "        return np.ones((self.c, self.p))\n",
    "    \n",
    "    def find_centroides(self, X, U):\n",
    "        u_m = U ** self.m\n",
    "        numerador = np.sum(u_m * X[:, np.newaxis, :], axis=0)\n",
    "        denominador = np.sum(u_m, axis=0)\n",
    "        denominador = np.fmax(denominador, np.finfo(np.float64).eps)\n",
    "        return numerador / denominador\n",
    "    \n",
    "    def get_distances(self, X, V):\n",
    "        return (X[:, np.newaxis, :] - V[np.newaxis, :, :]) ** 2\n",
    "\n",
    "    def update_u(self, D, Lambda):\n",
    "        power = 1.0 / (self.m - 1)\n",
    "        eps = np.finfo(np.float64).eps\n",
    "        \n",
    "        weighted_dist = D * Lambda\n",
    "        weighted_dist = np.fmax(weighted_dist, eps) \n",
    "        \n",
    "        term = weighted_dist ** (-power)\n",
    "        \n",
    "        denominator = np.sum(term, axis=(1, 2), keepdims=True)\n",
    "        denominator = np.fmax(denominator, eps)\n",
    "        \n",
    "        return term / denominator\n",
    "    \n",
    "    def update_lambda(self, D, U):\n",
    "        eps = np.finfo(np.float64).eps\n",
    "        \n",
    "        term_k = (U ** self.m) * np.fmax(D, eps)\n",
    "        S_ij = np.sum(term_k, axis=0) \n",
    "        \n",
    "        # Regularização Aditiva\n",
    "        ##\n",
    "        regularization_factor = 0.01 * self.global_var\n",
    "        S_ij = S_ij + regularization_factor \n",
    "        \n",
    "        prod_S = np.prod(S_ij, axis=1, keepdims=True)\n",
    "        numerator = prod_S ** (1.0 / self.p)\n",
    "        \n",
    "        Lambda = numerator / S_ij\n",
    "        \n",
    "        return Lambda\n",
    "\n",
    "    ##\n",
    "    def calculate_objective_function(self, D, U, Lambda):\n",
    "        term = (U ** self.m) * D\n",
    "        sum_k = np.sum(term, axis=0)\n",
    "        return np.sum(Lambda * sum_k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a5722d",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "024b9c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfcm_run(dados, num_clusters, m=2, max_iter=1000, epsilon=1e-6):\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(dados)\n",
    "    \n",
    "    mfcm = MFCM(c=num_clusters, X=X_scaled, m=m)\n",
    "    \n",
    "    indices = np.random.choice(X_scaled.shape[0], num_clusters, replace=False)\n",
    "    centroids = X_scaled[indices]\n",
    "    \n",
    "    Lambda = np.ones((num_clusters, X_scaled.shape[1]))\n",
    "    \n",
    "    D = mfcm.get_distances(X_scaled, centroids)\n",
    "    U = mfcm.update_u(D, Lambda)\n",
    "    \n",
    "    WARM_UP_ITERS = 20 \n",
    "\n",
    "    for i in range(max_iter):\n",
    "        U_old = U.copy()\n",
    "        \n",
    "        centroids = mfcm.find_centroides(X_scaled, U)\n",
    "        D = mfcm.get_distances(X_scaled, centroids)\n",
    "        \n",
    "        ##\n",
    "        if i >= WARM_UP_ITERS:\n",
    "            Lambda = mfcm.update_lambda(D, U) \n",
    "        \n",
    "        U = mfcm.update_u(D, Lambda)\n",
    "        \n",
    "        if np.linalg.norm(U - U_old) < epsilon:\n",
    "            break\n",
    "        \n",
    "    J_final = mfcm.calculate_objective_function(D, U, Lambda)\n",
    "    Delta = np.sum(U, axis=2)\n",
    "    \n",
    "    return centroids, U, Delta, Lambda, J_final"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f037a9b7",
   "metadata": {},
   "source": [
    "## Simulação de Monte Carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d1dc18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_objective_function(self, D, U, Lambda):\n",
    "        term = (U ** self.m) * D\n",
    "        sum_k = np.sum(term, axis=0)\n",
    "        weighted_sum = Lambda * sum_k\n",
    "        J = np.sum(weighted_sum)\n",
    "        return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb0e422f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_final_experiment(dados, labels, num_clusters=3, num_trials=100, restarts=50):\n",
    "    results_ari = []\n",
    "    results_ami = []\n",
    "    \n",
    "    for t in range(num_trials):\n",
    "        best_J = np.inf\n",
    "        best_pred = None\n",
    "        \n",
    "        for r in range(restarts):\n",
    "            try:\n",
    "                centroids, U, Delta, Lambda, J = mfcm_run(dados, num_clusters, m=2)\n",
    "                \n",
    "                if J > 1e-3 and J < best_J:\n",
    "                    best_J = J\n",
    "                    best_pred = np.argmax(Delta, axis=1)\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        if best_pred is not None:\n",
    "            ari = adjusted_rand_score(labels, best_pred)\n",
    "            ami = adjusted_mutual_info_score(labels, best_pred)\n",
    "            \n",
    "            results_ari.append(ari)\n",
    "            results_ami.append(ami)\n",
    "            \n",
    "            print(f\"Trial {t+1}: J={best_J:.4f} | ARI={ari:.4f} | AMI={ami:.4f}\")\n",
    "        else:\n",
    "            print(f\"Trial {t+1}: Falha (Singularidade em todas as tentativas).\")\n",
    "\n",
    "    print(f\"Mean ARI: {np.mean(results_ari):.4f} +/- {np.std(results_ari):.4f}\")\n",
    "    print(f\"Mean AMI: {np.mean(results_ami):.4f} +/- {np.std(results_ami):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f81e580",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_final_experiment(dados, labels, num_clusters=5, num_trials=100, restarts=50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
