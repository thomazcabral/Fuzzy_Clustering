{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tJsG3H__M7UL"
   },
   "source": [
    "# Fuzzy C-Means (FCM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "GAzys-jYM7UN"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dqs0lrF-M7UO"
   },
   "source": [
    "## Geração de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 73
    },
    "id": "9akebLpLNOvC",
    "outputId": "10afd9b1-573d-4e28-82e0-8fd2ce5a52dc"
   },
   "outputs": [],
   "source": [
    "def gerar_configuracao(mu_list, sigma_list, tamanhos, config_id):\n",
    "    dfs = []\n",
    "    for i, (mu, sigma2, n) in enumerate(zip(mu_list, sigma_list, tamanhos)):\n",
    "        Sigma = np.diag(sigma2)\n",
    "        data = np.random.multivariate_normal(mu, Sigma, n)\n",
    "        df = pd.DataFrame(data, columns=[\"x1\", \"x2\"])\n",
    "        df[\"class\"] = i + 1\n",
    "        dfs.append(df)\n",
    "    df_config = pd.concat(dfs, ignore_index=True)\n",
    "    df_config[\"config\"] = config_id\n",
    "    return df_config\n",
    "\n",
    "np.random.seed(42)  # reprodutibilidade\n",
    "\n",
    "# -------------------------------\n",
    "# Configuração 1\n",
    "mu_1 = [[5, 0], [15, 5], [18, 14]]\n",
    "sigma2_1 = [[81, 9], [9, 100], [25, 36]]\n",
    "n1 = [200, 100, 50]\n",
    "df1 = gerar_configuracao(mu_1, sigma2_1, n1, config_id=1)\n",
    "l1 = \"Classes elípticas de tamanhos diferentes\"\n",
    "\n",
    "# -------------------------------\n",
    "# Configuração 2\n",
    "mu_2 = [[0, 0], [30, 0], [12, 25]]\n",
    "sigma2_2 = [[100, 100], [49, 49], [16, 16]]\n",
    "n2 = [200, 100, 50]\n",
    "df2 = gerar_configuracao(mu_2, sigma2_2, n2, config_id=2)\n",
    "l2 = \"Classes esféricas de tamanhos diferentes\"\n",
    "\n",
    "# -------------------------------\n",
    "# Configuração 3\n",
    "mu_3 = [[0, 0], [15, 5], [15, -5]]\n",
    "sigma2_3 = [[100, 4], [100, 4], [100, 4]]\n",
    "n3 = [100, 100, 100]\n",
    "df3 = gerar_configuracao(mu_3, sigma2_3, n3, config_id=3)\n",
    "l3 = \"Classes elípticas de tamanhos iguais\"\n",
    "\n",
    "# -------------------------------\n",
    "# Configuração 4\n",
    "mu_4 = [[0, 0], [15, 0], [-15, 0]]\n",
    "sigma2_4 = [[16, 16], [16, 16], [16, 16]]\n",
    "n4 = [100, 100, 100]\n",
    "df4 = gerar_configuracao(mu_4, sigma2_4, n4, config_id=4)\n",
    "l4 = \"Classes elípticas de tamanhos iguais\"\n",
    "\n",
    "# -------------------------------\n",
    "# Configuração 5\n",
    "mu_5 = [[5, 0], [15, 5], [10, -7], [3, 15]]\n",
    "sigma2_5 = [[81, 9], [9, 100], [49, 16], [25, 25]]\n",
    "n5 = [50, 50, 50, 50]\n",
    "df5 = gerar_configuracao(mu_5, sigma2_5, n5, config_id=5)\n",
    "l5 = \"3 classes elípticas e 1 esférica\"\n",
    "\n",
    "# -------------------------------\n",
    "# Configuração 6\n",
    "mu_6 = [[5, 0], [15, 5], [12, -12], [7, 17]]\n",
    "sigma2_6 = [[81, 9], [9, 100], [16, 16], [25, 25]]\n",
    "n6 = [50, 50, 50, 50]\n",
    "df6 = gerar_configuracao(mu_6, sigma2_6, n6, config_id=6)\n",
    "l6 = \"2 classes elípticas e 2 esféricas\"\n",
    "\n",
    "# -------------------------------\n",
    "# Configuração 7\n",
    "mu_7 = [[0, 0], [18, 0], [-18, 0], [0, -12]]\n",
    "sigma2_7 = [[12, 12], [20, 20], [16, 16], [81, 20]]\n",
    "n7 = [50, 50, 50, 50]\n",
    "df7 = gerar_configuracao(mu_7, sigma2_7, n7, config_id=7)\n",
    "l7 = \"1 classe elíptica e 3 esféricas\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3uWXyt4TM7UP"
   },
   "source": [
    "### Verificando as classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "blQ09J4eM7UP",
    "outputId": "84ae0899-866e-4b95-aaa5-ca7b795dc0c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monte Carlo FCM Clustering Results for Config 1\n",
      "Mean Rand Index: 0.5801\n",
      "Standard Deviation of Rand Index: 0.0598\n",
      "\n",
      "\n",
      "Monte Carlo FCM Clustering Results for Config 2\n",
      "Mean Rand Index: 0.6487\n",
      "Standard Deviation of Rand Index: 0.0294\n",
      "\n",
      "\n",
      "Monte Carlo FCM Clustering Results for Config 3\n",
      "Mean Rand Index: 0.5320\n",
      "Standard Deviation of Rand Index: 0.0342\n",
      "\n",
      "\n",
      "Monte Carlo FCM Clustering Results for Config 4\n",
      "Mean Rand Index: 0.6725\n",
      "Standard Deviation of Rand Index: 0.0065\n",
      "\n",
      "\n",
      "Monte Carlo FCM Clustering Results for Config 5\n",
      "Mean Rand Index: 0.4863\n",
      "Standard Deviation of Rand Index: 0.0301\n",
      "\n",
      "\n",
      "Monte Carlo FCM Clustering Results for Config 6\n",
      "Mean Rand Index: 0.4937\n",
      "Standard Deviation of Rand Index: 0.0490\n",
      "\n",
      "\n",
      "Monte Carlo FCM Clustering Results for Config 7\n",
      "Mean Rand Index: 0.5290\n",
      "Standard Deviation of Rand Index: 0.0258\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def crisp_to_fuzzy(y, n_clusters): # transforma o dataset em fuzzy\n",
    "    fuzzy_labels = np.zeros((len(y), n_clusters)) # cria uma array do dataset preenchida só com zeros\n",
    "    for i, label in enumerate(y):\n",
    "        fuzzy_labels[i, label] = 1 # com base na classe, o zero é substituído por um\n",
    "    return fuzzy_labels\n",
    "\n",
    "def inicializao_matriz_pertinencia(num_amostras, num_clusters):\n",
    "    matriz_pertinencia = np.random.rand(num_amostras, num_clusters) # gera uma matriz inicial aleatória com valores entre 0 e 1\n",
    "    matriz_pertinencia = matriz_pertinencia / matriz_pertinencia.sum(axis=1, keepdims=True) # normalização da matriz pra garantir que a soma dos graus dê um\n",
    "    return matriz_pertinencia\n",
    "\n",
    "def atualizacao_centroides(dados, matriz_pertinencia, m):\n",
    "    matriz_pertinencia_m = matriz_pertinencia ** m # preparação dos graus de pertinência\n",
    "    centroides = np.dot(matriz_pertinencia_m.T, dados) / np.sum(matriz_pertinencia_m.T, axis=1, keepdims=True) # fórmula para o cálculo dos centroides\n",
    "    return centroides\n",
    "\n",
    "def atualizacao_matriz_pertinencia(dados, centroides, m):\n",
    "    matriz_distancias = np.linalg.norm(dados[:, np.newaxis] - centroides, axis=2) ** 2\n",
    "    matriz_distancias = np.fmax(matriz_distancias, np.finfo(np.float64).eps) # evita que matriz_distancias seja 0, np.finfo... é o menor número maior que zero aaqui\n",
    "    matriz_distancias_inversa = 1 / matriz_distancias\n",
    "    potencia = 1 / (m-1)\n",
    "    matriz_pertinencia_atualizada = matriz_distancias_inversa ** potencia / np.sum(matriz_distancias_inversa ** potencia, axis=1, keepdims=True) # fórmula para atualizar os graus de pertinência\n",
    "    return matriz_pertinencia_atualizada\n",
    "\n",
    "def fcm(dados, num_clusters, m=2, max_iter=1000, erro=1e-5):\n",
    "    num_amostras = dados.shape[0]\n",
    "    matriz_pertinencia = inicializao_matriz_pertinencia(num_amostras, num_clusters)\n",
    "    for _ in range(max_iter): # primeiro critério de parada\n",
    "        centroides = atualizacao_centroides(dados, matriz_pertinencia, m)\n",
    "        nova_matriz_pertinencia = atualizacao_matriz_pertinencia(dados, centroides, m)\n",
    "        if np.linalg.norm(nova_matriz_pertinencia - matriz_pertinencia) < erro: # segundo critério de parada\n",
    "            break\n",
    "        matriz_pertinencia = nova_matriz_pertinencia\n",
    "    return centroides, matriz_pertinencia\n",
    "\n",
    "def pertinence_distance(delta_k, delta_k_linha, c):\n",
    "    # calcula a distância entre δ_k e δ_k' (matrizes de pertinência)\n",
    "    return (1/c) * np.sum((delta_k - delta_k_linha) ** 2)\n",
    "\n",
    "def fuzzy_rand_index(particao1, particao2, c):\n",
    "    n = particao1.shape[0]\n",
    "    total_sum = 0\n",
    "\n",
    "    for k in range(n):\n",
    "        for k_linha in range(k+1, n):\n",
    "            if k != k_linha:\n",
    "                # calcula a métrica para P\n",
    "                delta_k = particao1[k]\n",
    "                delta_k_prime = particao1[k_linha]\n",
    "                EP = 1 - pertinence_distance(delta_k, delta_k_prime, c)\n",
    "\n",
    "                # calcula a métrica para Q\n",
    "                delta_k_Q = particao2[k]\n",
    "                delta_k_prime_Q = particao2[k_linha]\n",
    "                EQ = 1 - pertinence_distance(delta_k_Q, delta_k_prime_Q, c)\n",
    "\n",
    "                total_sum += np.abs(EP - EQ) # soma a diferença absoluta entre EP e EQ\n",
    "\n",
    "    denominador = n * (n - 1) / 2\n",
    "    if denominador == 0:\n",
    "        raise ValueError\n",
    "\n",
    "    return 1- (total_sum / denominador)\n",
    "\n",
    "def simulacao_monte_carlo(dados, part_dif, num_clusters, num_trials):\n",
    "    indices_rand = []\n",
    "    for _ in range(num_trials):\n",
    "        #print(_)\n",
    "        centroides, matriz_pertinencia = fcm(dados, num_clusters)\n",
    "        predicted_labels = np.argmax(matriz_pertinencia, axis=1)\n",
    "        idx_rand = fuzzy_rand_index(part_dif, predicted_labels, num_clusters)\n",
    "        indices_rand.append(idx_rand)\n",
    "    mean_rand_index = np.mean(indices_rand)\n",
    "    std_rand_index = np.std(indices_rand)\n",
    "    return mean_rand_index, std_rand_index\n",
    "i = 1\n",
    "for df in [df1, df2, df3, df4, df5, df6, df7]:\n",
    "    if i == 5 or i == 6 or i == 7:\n",
    "        num_clusters = 4\n",
    "    else:\n",
    "        num_clusters = 3\n",
    "    df.drop(\"config\", axis=1, inplace=True)\n",
    "    if i == 5 or i == 6 or i == 7:\n",
    "        df[\"class\"].replace({1: 0, 2: 1, 3: 2, 4: 3}, inplace=True)\n",
    "    else: \n",
    "        df[\"class\"].replace({1: 0, 2: 1, 3: 2}, inplace=True)\n",
    "    part_dif = df[\"class\"].values\n",
    "    df.drop(\"class\", axis=1, inplace=True)\n",
    "    dados = df.to_numpy()\n",
    "    part_dif = crisp_to_fuzzy(part_dif, num_clusters)\n",
    "    num_trials = 100\n",
    "    media_indice_rand, dp_indice_rand = simulacao_monte_carlo(dados, part_dif, num_clusters, num_trials)\n",
    "    print(f\"Monte Carlo FCM Clustering Results for Config {i}\")\n",
    "    print(f\"Mean Rand Index: {media_indice_rand:.4f}\") # 4 casas decimais\n",
    "    print(f\"Standard Deviation of Rand Index: {dp_indice_rand:.4f}\") # 4 casas decimais\n",
    "    print(\"\\n\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parâmetros das configurações\n",
    "params_config_12 = [\n",
    "    {'mu': [-16, -5], 'sigma': [20, 20], 'n': 50},\n",
    "    {'mu': [-8, 8], 'sigma': [13, 13], 'n': 100},\n",
    "    {'mu': [0, 0], 'sigma': [6, 6], 'n': 200},\n",
    "]\n",
    "\n",
    "params_config_13 = [\n",
    "    {'mu': [7, -6], 'sigma': [50, 5], 'n': 100},\n",
    "    {'mu': [0, 0], 'sigma': [2, 50], 'n': 100},\n",
    "    {'mu': [12, 0], 'sigma': [50, 5], 'n': 100},\n",
    "]\n",
    "\n",
    "# Faixa para ruído e semente aleatória\n",
    "noise_range = [-100, 50]\n",
    "np.random.seed(42)\n",
    "\n",
    "# Função de geração de dados com ruído\n",
    "def generate_data(config_params, noise_percent):\n",
    "    data_all = []\n",
    "    for class_idx, param in enumerate(config_params, start=1):\n",
    "        mu = np.array(param['mu'])\n",
    "        sigma_diag = np.diag(param['sigma'])\n",
    "        n = param['n']\n",
    "        n_noise = int(n * noise_percent / 100)\n",
    "        n_signal = n - n_noise\n",
    "\n",
    "        real_data = np.random.multivariate_normal(mu, sigma_diag, n_signal)\n",
    "        labels_real = np.full((n_signal,), class_idx)\n",
    "\n",
    "        noise_data = np.random.uniform(noise_range[0], noise_range[1], size=(n_noise, 2))\n",
    "        labels_noise = np.full((n_noise,), 0)\n",
    "\n",
    "        data = np.vstack([real_data, noise_data])\n",
    "        labels = np.concatenate([labels_real, labels_noise])\n",
    "\n",
    "        df = pd.DataFrame(data, columns=['x1', 'x2'])\n",
    "        df['class'] = labels\n",
    "        data_all.append(df)\n",
    "\n",
    "    return pd.concat(data_all, ignore_index=True)\n",
    "\n",
    "# Configurações e títulos\n",
    "configs = [\n",
    "    (params_config_12, 10),\n",
    "    (params_config_12, 20),\n",
    "    (params_config_12, 30),\n",
    "    (params_config_13, 10),\n",
    "    (params_config_13, 20),\n",
    "    (params_config_13, 30),\n",
    "]\n",
    "\n",
    "titles = [\n",
    "    \"Configuração 12 - 10% ruído\",\n",
    "    \"Configuração 12 - 20% ruído\",\n",
    "    \"Configuração 12 - 30% ruído\",\n",
    "    \"Configuração 13 - 10% ruído\",\n",
    "    \"Configuração 13 - 20% ruído\",\n",
    "    \"Configuração 13 - 30% ruído\",\n",
    "]\n",
    "\n",
    "# Geração dos DataFrames separadamente\n",
    "dfs_por_config = {}\n",
    "\n",
    "for (params, noise), title in zip(configs, titles):\n",
    "    df = generate_data(params, noise)\n",
    "    df['classe_legenda'] = df['class'].replace(0, 'ruído')\n",
    "    dfs_por_config[title] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Resultados de Monte Carlo para Configuração 12 - 10% ruído (100 tentativas)\n",
      "Média do Índice Rand: 0.6260\n",
      "Desvio Padrão do Índice Rand: 0.1399\n",
      "\n",
      "\n",
      "Resultados de Monte Carlo para Configuração 12 - 20% ruído (100 tentativas)\n",
      "Média do Índice Rand: 0.5962\n",
      "Desvio Padrão do Índice Rand: 0.1199\n",
      "\n",
      "\n",
      "Resultados de Monte Carlo para Configuração 12 - 30% ruído (100 tentativas)\n",
      "Média do Índice Rand: 0.5412\n",
      "Desvio Padrão do Índice Rand: 0.1457\n",
      "\n",
      "\n",
      "Resultados de Monte Carlo para Configuração 13 - 10% ruído (100 tentativas)\n",
      "Média do Índice Rand: 0.4884\n",
      "Desvio Padrão do Índice Rand: 0.1531\n",
      "\n",
      "\n",
      "Resultados de Monte Carlo para Configuração 13 - 20% ruído (100 tentativas)\n",
      "Média do Índice Rand: 0.4826\n",
      "Desvio Padrão do Índice Rand: 0.1934\n",
      "\n",
      "\n",
      "Resultados de Monte Carlo para Configuração 13 - 30% ruído (100 tentativas)\n",
      "Média do Índice Rand: 0.5232\n",
      "Desvio Padrão do Índice Rand: 0.1311\n"
     ]
    }
   ],
   "source": [
    "for nome_config, df in dfs_por_config.items():\n",
    "    num_clusters = 4\n",
    "    labels = df[\"class\"].values\n",
    "    labels = crisp_to_fuzzy(labels, num_clusters)\n",
    "    df.drop(\"class\", axis=1, inplace=True)\n",
    "    df.drop(\"classe_legenda\", axis=1, inplace=True)\n",
    "    dados = df.to_numpy()\n",
    "    num_trials = 100\n",
    "    media_indice_rand, dp_indice_rand = simulacao_monte_carlo(dados, labels, num_clusters, num_trials)\n",
    "    print(\"\\n\")\n",
    "    print(f\"Resultados de Monte Carlo para {nome_config} ({num_trials} tentativas)\")\n",
    "    print(f\"Média do Índice Rand: {media_indice_rand:.4f}\")\n",
    "    print(f\"Desvio Padrão do Índice Rand: {dp_indice_rand:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
