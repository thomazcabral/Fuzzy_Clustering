{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X-5_kzR-_0cO"
   },
   "source": [
    "## Tratamento dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VnzujkKg_6xC"
   },
   "source": [
    "### Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "v9xQo6eL_vTW"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.metrics import adjusted_mutual_info_score\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inicializacao_matriz_pertinencia(num_amostras, num_clusters):\n",
    "    matriz_pertinencia = np.random.rand(num_amostras, num_clusters) # gera uma matriz inicial aleatória com valores entre 0 e 1\n",
    "    matriz_pertinencia = matriz_pertinencia / matriz_pertinencia.sum(axis=1, keepdims=True) # normalização da matriz pra garantir que a soma dos graus dê um\n",
    "    return matriz_pertinencia\n",
    "def inicializacao_pesos(num_variaveis):\n",
    "    pesos = np.ones(num_variaveis) / num_variaveis # pesos iguais somam 1\n",
    "    return pesos\n",
    "def atualizacao_centroides(dados, matriz_pertinencia, m):\n",
    "    matriz_pertinencia_m = matriz_pertinencia ** m # preparação dos graus de pertinência\n",
    "    centroides = np.dot(matriz_pertinencia_m.T, dados) / np.sum(matriz_pertinencia_m.T, axis=1, keepdims=True) # fórmula para o cálculo dos centroides\n",
    "    return centroides\n",
    "def atualizacao_matriz_pertinencia(dados, centroides, pesos, m, beta):\n",
    "    diff_sq = (dados[:, np.newaxis, :] - centroides) ** 2 # diferença ao quadrado (x_kj - y_ij)^2\n",
    "    pesos_potencia = pesos ** beta\n",
    "    weighted_diff_sq = pesos_potencia * diff_sq # aplica o peso elevado\n",
    "    matriz_distancias = np.sum(weighted_diff_sq, axis=2) # d_ik^(w)^2 = sum_j( w_j^beta * (x_kj - y_ij)^2 )\n",
    "    matriz_distancias = np.fmax(matriz_distancias, np.finfo(np.float64).eps)\n",
    "    potencia = 1.0 / (m - 1)\n",
    "    matriz_distancias_inversa = 1 / matriz_distancias # fórmula transformada: u_ik = (1/d_ik^2)^P / sum_h( (1/d_hk^2)^P )\n",
    "    num = matriz_distancias_inversa ** potencia\n",
    "    den = np.sum(num, axis=1, keepdims=True) # sum_h( (1/d_hk^2)^P )\n",
    "    nova_matriz_pertinencia = num / den\n",
    "    nova_matriz_pertinencia = nova_matriz_pertinencia / np.sum(nova_matriz_pertinencia, axis=1, keepdims=True)\n",
    "    return nova_matriz_pertinencia\n",
    "def atualizacao_pesos(dados, centroides, matriz_pertinencia, beta):\n",
    "    matriz_pertinencia_broadcast = matriz_pertinencia[:, :, np.newaxis] \n",
    "    diff_sq = (dados[:, np.newaxis, :] - centroides) ** 2 # diferença ao quadrado (x_kj - y_ij)^2\n",
    "    weighted_diff_sq = matriz_pertinencia_broadcast * diff_sq # multiplicação\n",
    "    D_j = np.sum(weighted_diff_sq, axis=(0, 1))\n",
    "    D_j = np.fmax(D_j, np.finfo(np.float64).eps)\n",
    "    beta_exponente = 1.0 / np.fmax(beta - 1, np.finfo(np.float64).eps) # 1 / (beta - 1)\n",
    "    razao = D_j[:, np.newaxis] / D_j[np.newaxis, :] # D_j / D_t\n",
    "    razao_potencia = razao ** beta_exponente\n",
    "    soma_termos = np.sum(razao_potencia, axis=1) # sum_t\n",
    "    pesos = 1.0 / soma_termos # tem no paper original\n",
    "    pesos = pesos / np.sum(pesos) # pesos somam 1\n",
    "    return pesos\n",
    "def fcm(dados, num_clusters, m=2, beta=2, max_iter=10**6, erro=1e-9):\n",
    "    num_amostras, num_variaveis = dados.shape\n",
    "    matriz_pertinencia = inicializacao_matriz_pertinencia(num_amostras, num_clusters)\n",
    "    pesos = inicializacao_pesos(num_variaveis)\n",
    "    for _ in range(max_iter): # primeiro critério de parada\n",
    "        centroides = atualizacao_centroides(dados, matriz_pertinencia, m)\n",
    "        nova_matriz_pertinencia = atualizacao_matriz_pertinencia(dados, centroides, pesos, m, beta)\n",
    "        pesos = atualizacao_pesos(dados, centroides, nova_matriz_pertinencia, beta)\n",
    "        if np.linalg.norm(nova_matriz_pertinencia - matriz_pertinencia) < erro: # segundo critério de parada\n",
    "            break\n",
    "        matriz_pertinencia = nova_matriz_pertinencia\n",
    "    return centroides, matriz_pertinencia, pesos\n",
    "def indice_rand(labels, predicted_labels):\n",
    "    return adjusted_rand_score(labels, predicted_labels)\n",
    "def simulacao_monte_carlo(dados, labels, num_clusters, num_trials):\n",
    "    ari = []\n",
    "    ami = []\n",
    "    for _ in range(num_trials):\n",
    "        centroides, matriz_pertinencia, pesos = fcm(dados, num_clusters)\n",
    "        predicted_labels = np.argmax(matriz_pertinencia, axis=1)\n",
    "        idx_rand = indice_rand(labels, predicted_labels)\n",
    "        ari.append(idx_rand)\n",
    "        ami_rand = adjusted_mutual_info_score(labels, predicted_labels)\n",
    "        ami.append(ami_rand)\n",
    "    mean_ari = np.mean(ari)\n",
    "    std_ari = np.std(ari)\n",
    "    mean_ami = np.mean(ami)\n",
    "    std_ami = np.std(ami)\n",
    "    return mean_ari, std_ari, mean_ami, std_ami"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_configuracao(mu_list, sigma_list, tamanhos, config_id):\n",
    "    dfs = []\n",
    "    for i, (mu, sigma2, n) in enumerate(zip(mu_list, sigma_list, tamanhos)):\n",
    "        Sigma = np.diag(sigma2)\n",
    "        data = np.random.multivariate_normal(mu, Sigma, n)\n",
    "        df = pd.DataFrame(data, columns=[\"x1\", \"x2\"])\n",
    "        df[\"class\"] = i + 1\n",
    "        dfs.append(df)\n",
    "    df_config = pd.concat(dfs, ignore_index=True)\n",
    "    df_config[\"config\"] = config_id\n",
    "    return df_config\n",
    "\n",
    "np.random.seed(42)  # reprodutibilidade\n",
    "\n",
    "# Configuração 1\n",
    "mu_1 = [[5, 0], [15, 5], [18, 14]]\n",
    "sigma2_1 = [[81, 9], [9, 100], [25, 36]]\n",
    "n1 = [200, 100, 50]\n",
    "df1 = gerar_configuracao(mu_1, sigma2_1, n1, config_id=1)\n",
    "l1 = \"Classes elípticas de tamanhos diferentes\"\n",
    "\n",
    "# Configuração 2\n",
    "mu_2 = [[0, 0], [30, 0], [12, 25]]\n",
    "sigma2_2 = [[100, 100], [49, 49], [16, 16]]\n",
    "n2 = [200, 100, 50]\n",
    "df2 = gerar_configuracao(mu_2, sigma2_2, n2, config_id=2)\n",
    "l2 = \"Classes esféricas de tamanhos diferentes\"\n",
    "\n",
    "# Configuração 3\n",
    "mu_3 = [[0, 0], [15, 5], [15, -5]]\n",
    "sigma2_3 = [[100, 4], [100, 4], [100, 4]]\n",
    "n3 = [100, 100, 100]\n",
    "df3 = gerar_configuracao(mu_3, sigma2_3, n3, config_id=3)\n",
    "l3 = \"Classes elípticas de tamanhos iguais\"\n",
    "\n",
    "# Configuração 4\n",
    "mu_4 = [[0, 0], [15, 0], [-15, 0]]\n",
    "sigma2_4 = [[16, 16], [16, 16], [16, 16]]\n",
    "n4 = [100, 100, 100]\n",
    "df4 = gerar_configuracao(mu_4, sigma2_4, n4, config_id=4)\n",
    "l4 = \"Classes esféricas de tamanhos iguais\"\n",
    "\n",
    "# Configuração 5\n",
    "mu_5 = [[5, 0], [15, 5], [10, -7], [3, 15]]\n",
    "sigma2_5 = [[81, 9], [9, 100], [49, 16], [25, 25]]\n",
    "n5 = [50, 50, 50, 50]\n",
    "df5 = gerar_configuracao(mu_5, sigma2_5, n5, config_id=5)\n",
    "l5 = \"3 classes elípticas e 1 esférica\"\n",
    "\n",
    "# Configuração 6\n",
    "mu_6 = [[5, 0], [15, 5], [12, -12], [7, 17]]\n",
    "sigma2_6 = [[81, 9], [9, 100], [16, 16], [25, 25]]\n",
    "n6 = [50, 50, 50, 50]\n",
    "df6 = gerar_configuracao(mu_6, sigma2_6, n6, config_id=6)\n",
    "l6 = \"2 classes elípticas e 2 esféricas\"\n",
    "\n",
    "# Configuração 7\n",
    "mu_7 = [[0, 0], [18, 0], [-18, 0], [0, -12]]\n",
    "sigma2_7 = [[12, 12], [20, 20], [16, 16], [81, 20]]\n",
    "n7 = [50, 50, 50, 50]\n",
    "df7 = gerar_configuracao(mu_7, sigma2_7, n7, config_id=7)\n",
    "l7 = \"1 classe elíptica e 3 esféricas\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuração 1\n",
      "ARI mean: 0.2978\n",
      "ARI std: 0.0000\n",
      "AMI mean: 0.4096\n",
      "AMI std: 0.0000\n",
      "\n",
      "Configuração 2\n",
      "ARI mean: 0.4874\n",
      "ARI std: 0.1212\n",
      "AMI mean: 0.5173\n",
      "AMI std: 0.0968\n",
      "\n",
      "Configuração 3\n",
      "ARI mean: 0.6417\n",
      "ARI std: 0.0000\n",
      "AMI mean: 0.6044\n",
      "AMI std: 0.0000\n",
      "\n",
      "Configuração 4\n",
      "ARI mean: -0.0050\n",
      "ARI std: 0.0000\n",
      "AMI mean: -0.0049\n",
      "AMI std: 0.0000\n",
      "\n",
      "Configuração 5\n",
      "ARI mean: 0.1320\n",
      "ARI std: 0.0000\n",
      "AMI mean: 0.2081\n",
      "AMI std: 0.0000\n",
      "\n",
      "Configuração 6\n",
      "ARI mean: 0.1568\n",
      "ARI std: 0.0000\n",
      "AMI mean: 0.2235\n",
      "AMI std: 0.0000\n",
      "\n",
      "Configuração 7\n",
      "ARI mean: 0.2324\n",
      "ARI std: 0.0000\n",
      "AMI mean: 0.2996\n",
      "AMI std: 0.0000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "i = 1\n",
    "for df in [df1, df2, df3, df4, df5, df6, df7]:\n",
    "    np.random.seed(42)  # reprodutibilidade\n",
    "    df.drop(\"config\", axis=1, inplace=True)  # remove a coluna de configuração\n",
    "    labels = df[\"class\"].values\n",
    "    num_clusters = len(df[df['class'] != 0]['class'].unique())  # número de clusters, excluindo o ruído\n",
    "    df.drop(\"class\", axis=1, inplace=True)  # remove a coluna de classe\n",
    "    dados = df.to_numpy()\n",
    "    num_trials = 100\n",
    "    mean_ari, std_ari, mean_ami, std_ami = simulacao_monte_carlo(dados, labels, num_clusters, num_trials)\n",
    "    print(f\"Configuração {i}\")\n",
    "    print(f\"ARI mean: {mean_ari:.4f}\")\n",
    "    print(f\"ARI std: {std_ari:.4f}\")\n",
    "    print(f\"AMI mean: {mean_ami:.4f}\")\n",
    "    print(f\"AMI std: {std_ami:.4f}\")\n",
    "    print(\"\")\n",
    "    i +=1"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
