{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X-5_kzR-_0cO"
   },
   "source": [
    "## Tratamento dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VnzujkKg_6xC"
   },
   "source": [
    "### Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "v9xQo6eL_vTW"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Geração de dados sintéticos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gerar dados com ruído nas 7 configurações acima\n",
    "# Ruído de 5%, 10% e 15% em relação ao total de dados\n",
    "# Intervalo de ruído: [-100, 50]\n",
    "\n",
    "def generate_data(config_params, noise_percent):\n",
    "    data_all = []\n",
    "    for class_idx, param in enumerate(config_params, start=1):\n",
    "        mu = np.array(param['mu'])\n",
    "        sigma_diag = np.diag(param['sigma'])\n",
    "        n = param['n']\n",
    "        n_noise = int(n * noise_percent / 100)\n",
    "        n_signal = n - n_noise\n",
    "\n",
    "        real_data = np.random.multivariate_normal(mu, sigma_diag, n_signal)\n",
    "        labels_real = np.full((n_signal,), class_idx)\n",
    "\n",
    "        noise_data = np.random.uniform(noise_range[0], noise_range[1], size=(n_noise, 2))\n",
    "        labels_noise = np.full((n_noise,), 0)\n",
    "\n",
    "        data = np.vstack([real_data, noise_data])\n",
    "        labels = np.concatenate([labels_real, labels_noise])\n",
    "\n",
    "        df = pd.DataFrame(data, columns=['x1', 'x2'])\n",
    "        df['class'] = labels\n",
    "        data_all.append(df)\n",
    "\n",
    "    return pd.concat(data_all, ignore_index=True)\n",
    "\n",
    "configurations = {\n",
    "    1: {'mu': [[5, 0], [15, 5], [18, 14]],\n",
    "        'sigma': [[81, 9], [9, 100], [25, 36]],\n",
    "        'n': [200, 100, 50]},\n",
    "    2: {'mu': [[0, 0], [30, 0], [12, 25]],\n",
    "        'sigma': [[100, 100], [49, 49], [16, 16]],\n",
    "        'n': [200, 100, 50]},\n",
    "    3: {'mu': [[0, 0], [15, 5], [15, -5]],\n",
    "        'sigma': [[100, 4], [100, 4], [100, 4]],\n",
    "        'n': [100, 100, 100]},\n",
    "    4: {'mu': [[0, 0], [15, 0], [-15, 0]],\n",
    "        'sigma': [[16, 16], [16, 16], [16, 16]],\n",
    "        'n': [100, 100, 100]},\n",
    "    5: {'mu': [[5, 0], [15, 5], [10, -7], [3, 15]],\n",
    "        'sigma': [[81, 9], [9, 100], [49, 16], [25, 25]],\n",
    "        'n': [50, 50, 50, 50]},\n",
    "    6: {'mu': [[5, 0], [15, 5], [12, -12], [7, 17]],\n",
    "        'sigma': [[81, 9], [9, 100], [16, 16], [25, 25]],\n",
    "        'n': [50, 50, 50, 50]},\n",
    "    7: {'mu': [[0, 0], [18, 0], [-18, 0], [0, -12]],\n",
    "        'sigma': [[12, 12], [20, 20], [16, 16], [81, 20]],\n",
    "        'n': [50, 50, 50, 50]},\n",
    "}\n",
    "\n",
    "noise_range = (-100, 50)\n",
    "\n",
    "noise_levels = [5, 10, 15]\n",
    "\n",
    "all_datasets = {}  # Key: (config_id, noise_level), Value: DataFrame\n",
    "\n",
    "for row_idx, noise in enumerate(noise_levels):\n",
    "    for col_idx, config_id in enumerate(sorted(configurations.keys())):\n",
    "        config = configurations[config_id]\n",
    "        config_params = [{'mu': mu, 'sigma': sigma, 'n': n}\n",
    "                         for mu, sigma, n in zip(config['mu'], config['sigma'], config['n'])]\n",
    "\n",
    "        df = generate_data(config_params, noise)\n",
    "\n",
    "        # Store the data\n",
    "        all_datasets[(config_id, noise)] = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "97ZB6HLiABGf"
   },
   "source": [
    "### Escolhendo e verificando um dos conjuntos gerados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 5)\n",
      "Mean Rand Index: 0.3193\n",
      "Standard Deviation of Rand Index: 0.0000\n",
      "(2, 5)\n",
      "Mean Rand Index: 0.4316\n",
      "Standard Deviation of Rand Index: 0.0000\n",
      "(3, 5)\n",
      "Mean Rand Index: 0.1267\n",
      "Standard Deviation of Rand Index: 0.0000\n",
      "(4, 5)\n",
      "Mean Rand Index: 0.8159\n",
      "Standard Deviation of Rand Index: 0.0000\n",
      "(5, 5)\n",
      "Mean Rand Index: 0.4126\n",
      "Standard Deviation of Rand Index: 0.0553\n",
      "(6, 5)\n",
      "Mean Rand Index: 0.4824\n",
      "Standard Deviation of Rand Index: 0.0130\n",
      "(7, 5)\n",
      "Mean Rand Index: 0.6861\n",
      "Standard Deviation of Rand Index: 0.0089\n",
      "(1, 10)\n",
      "Mean Rand Index: 0.2919\n",
      "Standard Deviation of Rand Index: 0.0009\n",
      "(2, 10)\n",
      "Mean Rand Index: 0.5541\n",
      "Standard Deviation of Rand Index: 0.0000\n",
      "(3, 10)\n",
      "Mean Rand Index: 0.1825\n",
      "Standard Deviation of Rand Index: 0.0000\n",
      "(4, 10)\n",
      "Mean Rand Index: 0.7975\n",
      "Standard Deviation of Rand Index: 0.0000\n",
      "(5, 10)\n",
      "Mean Rand Index: 0.2901\n",
      "Standard Deviation of Rand Index: 0.0000\n",
      "(6, 10)\n",
      "Mean Rand Index: 0.5066\n",
      "Standard Deviation of Rand Index: 0.0210\n",
      "(7, 10)\n",
      "Mean Rand Index: 0.6930\n",
      "Standard Deviation of Rand Index: 0.0191\n",
      "(1, 15)\n",
      "Mean Rand Index: 0.3482\n",
      "Standard Deviation of Rand Index: 0.0198\n",
      "(2, 15)\n",
      "Mean Rand Index: 0.5283\n",
      "Standard Deviation of Rand Index: 0.0000\n",
      "(3, 15)\n",
      "Mean Rand Index: 0.2207\n",
      "Standard Deviation of Rand Index: 0.0134\n",
      "(4, 15)\n",
      "Mean Rand Index: 0.6947\n",
      "Standard Deviation of Rand Index: 0.0283\n",
      "(5, 15)\n",
      "Mean Rand Index: 0.3460\n",
      "Standard Deviation of Rand Index: 0.0203\n",
      "(6, 15)\n",
      "Mean Rand Index: 0.4202\n",
      "Standard Deviation of Rand Index: 0.0190\n",
      "(7, 15)\n",
      "Mean Rand Index: 0.6656\n",
      "Standard Deviation of Rand Index: 0.0076\n"
     ]
    }
   ],
   "source": [
    "for (config_id, noise_level), df in all_datasets.items():\n",
    "    labels = df[\"class\"].values\n",
    "    num_clusters = len(df['class'].unique())\n",
    "    df.drop(\"class\", axis=1, inplace=True)\n",
    "    dados = df.to_numpy()\n",
    "    def inicializacao_matriz_pertinencia(num_amostras, num_clusters):\n",
    "        matriz_pertinencia = np.random.rand(num_amostras, num_clusters) # gera uma matriz inicial aleatória com valores entre 0 e 1\n",
    "        matriz_pertinencia = matriz_pertinencia / matriz_pertinencia.sum(axis=1, keepdims=True) # normalização da matriz pra garantir que a soma dos graus dê um\n",
    "        return matriz_pertinencia\n",
    "    def atualizacao_centroides(dados, matriz_pertinencia, m):\n",
    "        matriz_pertinencia_m = matriz_pertinencia ** m # preparação dos graus de pertinência\n",
    "        centroides = np.dot(matriz_pertinencia_m.T, dados) / np.sum(matriz_pertinencia_m.T, axis=1, keepdims=True) # fórmula para o cálculo dos centroides\n",
    "        return centroides\n",
    "    def atualizacao_matriz_pertinencia(dados, centroides, m):\n",
    "        # dados[:, np.newaxis] - centroides cria uma matriz de diferenças entre os pontos de dados e os centroides\n",
    "        # np.linalg.norm(..., axis=2) calcula a norma (distância euclidiana) das diferenças\n",
    "        # ** 2 para a distância ser a quadrada\n",
    "        matriz_distancias = np.linalg.norm(dados[:, np.newaxis] - centroides, axis=2) ** 2\n",
    "        matriz_distancias = np.fmax(matriz_distancias, np.finfo(np.float64).eps) # evita que matriz_distancias seja 0, np.finfo... é o menor número maior que zero aaqui\n",
    "        matriz_distancias_inversa = 1 / matriz_distancias\n",
    "        potencia = 1 / (m-1)\n",
    "        matriz_pertinencia_atualizada = matriz_distancias_inversa ** potencia/ np.sum(matriz_distancias_inversa ** potencia, axis=1, keepdims=True) # fórmula para atualizar os graus de pertinência\n",
    "        return matriz_pertinencia_atualizada\n",
    "    def fcm(dados, num_clusters, m=2, max_iter=10**6, erro=1e-9):\n",
    "        num_amostras = dados.shape[0]\n",
    "        matriz_pertinencia = inicializacao_matriz_pertinencia(num_amostras, num_clusters)\n",
    "        for _ in range(max_iter): # primeiro critério de parada\n",
    "            centroides = atualizacao_centroides(dados, matriz_pertinencia, m)\n",
    "            nova_matriz_pertinencia = atualizacao_matriz_pertinencia(dados, centroides, m)\n",
    "            if np.linalg.norm(nova_matriz_pertinencia - matriz_pertinencia) < erro: # segundo critério de parada\n",
    "                break\n",
    "            matriz_pertinencia = nova_matriz_pertinencia\n",
    "        return centroides, matriz_pertinencia\n",
    "    def indice_rand(labels, predicted_labels):\n",
    "        return adjusted_rand_score(labels, predicted_labels)\n",
    "    def simulacao_monte_carlo(dados, labels, num_clusters, num_trials):\n",
    "        indices_rand = []\n",
    "        for _ in range(num_trials):\n",
    "            centroides, matriz_pertinencia = fcm(dados, num_clusters)\n",
    "            predicted_labels = np.argmax(matriz_pertinencia, axis=1)\n",
    "            #print(predicted_labels)\n",
    "            idx_rand = indice_rand(labels, predicted_labels)\n",
    "            indices_rand.append(idx_rand)\n",
    "        mean_rand_index = np.mean(indices_rand)\n",
    "        std_rand_index = np.std(indices_rand)\n",
    "        return mean_rand_index, std_rand_index\n",
    "    num_trials = 100\n",
    "    media_indice_rand, dp_indice_rand = simulacao_monte_carlo(dados, labels, num_clusters, num_trials)\n",
    "\n",
    "    print((config_id, noise_level))\n",
    "    print(f\"Mean Rand Index: {media_indice_rand:.4f}\")\n",
    "    print(f\"Standard Deviation of Rand Index: {dp_indice_rand:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados\n",
    "\n",
    "Configuração 1:  \n",
    "Mean Rand Index: 0.2943  \n",
    "Standard Deviation of Rand Index: 0.0000  \n",
    "\n",
    "Configuração 2:  \n",
    "Mean Rand Index: 0.6129  \n",
    "Standard Deviation of Rand Index: 0.0000  \n",
    "\n",
    "Configuração 3:  \n",
    "Mean Rand Index: 0.1285  \n",
    "Standard Deviation of Rand Index: 0.0000  \n",
    "\n",
    "Configuração 4:  \n",
    "Mean Rand Index: 0.8470  \n",
    "Standard Deviation of Rand Index: 0.0000  \n",
    "\n",
    "Configuração 5:  \n",
    "Mean Rand Index: 0.4291  \n",
    "Standard Deviation of Rand Index: 0.0000  \n",
    "\n",
    "Configuração 6:  \n",
    "Mean Rand Index: 0.4814  \n",
    "Standard Deviation of Rand Index: 0.0000  \n",
    "\n",
    "Configuração 7:  \n",
    "Mean Rand Index: 0.7653  \n",
    "Standard Deviation of Rand Index: 0.0000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parâmetros das configurações\n",
    "params_config_12 = [\n",
    "    {'mu': [-16, -5], 'sigma': [20, 20], 'n': 50},\n",
    "    {'mu': [-8, 8], 'sigma': [13, 13], 'n': 100},\n",
    "    {'mu': [0, 0], 'sigma': [6, 6], 'n': 200},\n",
    "]\n",
    "\n",
    "params_config_13 = [\n",
    "    {'mu': [7, -6], 'sigma': [50, 5], 'n': 100},\n",
    "    {'mu': [0, 0], 'sigma': [2, 50], 'n': 100},\n",
    "    {'mu': [12, 0], 'sigma': [50, 5], 'n': 100},\n",
    "]\n",
    "\n",
    "# Faixa para ruído e semente aleatória\n",
    "noise_range = [-100, 50]\n",
    "np.random.seed(42)\n",
    "\n",
    "# Função de geração de dados com ruído\n",
    "def generate_data(config_params, noise_percent):\n",
    "    data_all = []\n",
    "    for class_idx, param in enumerate(config_params, start=1):\n",
    "        mu = np.array(param['mu'])\n",
    "        sigma_diag = np.diag(param['sigma'])\n",
    "        n = param['n']\n",
    "        n_noise = int(n * noise_percent / 100)\n",
    "        n_signal = n - n_noise\n",
    "\n",
    "        real_data = np.random.multivariate_normal(mu, sigma_diag, n_signal)\n",
    "        labels_real = np.full((n_signal,), class_idx)\n",
    "\n",
    "        noise_data = np.random.uniform(noise_range[0], noise_range[1], size=(n_noise, 2))\n",
    "        labels_noise = np.full((n_noise,), 0)\n",
    "\n",
    "        data = np.vstack([real_data, noise_data])\n",
    "        labels = np.concatenate([labels_real, labels_noise])\n",
    "\n",
    "        df = pd.DataFrame(data, columns=['x1', 'x2'])\n",
    "        df['class'] = labels\n",
    "        data_all.append(df)\n",
    "\n",
    "    return pd.concat(data_all, ignore_index=True)\n",
    "\n",
    "# Configurações e títulos\n",
    "configs = [\n",
    "    (params_config_12, 10),\n",
    "    (params_config_12, 20),\n",
    "    (params_config_12, 30),\n",
    "    (params_config_13, 10),\n",
    "    (params_config_13, 20),\n",
    "    (params_config_13, 30),\n",
    "]\n",
    "\n",
    "titles = [\n",
    "    \"Configuração 12 - 10% ruído\",\n",
    "    \"Configuração 12 - 20% ruído\",\n",
    "    \"Configuração 12 - 30% ruído\",\n",
    "    \"Configuração 13 - 10% ruído\",\n",
    "    \"Configuração 13 - 20% ruído\",\n",
    "    \"Configuração 13 - 30% ruído\",\n",
    "]\n",
    "\n",
    "# Geração dos DataFrames separadamente\n",
    "dfs_por_config = {}\n",
    "\n",
    "for (params, noise), title in zip(configs, titles):\n",
    "    df = generate_data(params, noise)\n",
    "    df['classe_legenda'] = df['class'].replace(0, 'ruído')\n",
    "    dfs_por_config[title] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Resultados de Monte Carlo para Configuração 12 - 10% ruído (100 tentativas)\n",
      "Média do Índice Rand: 0.8424\n",
      "Desvio Padrão do Índice Rand: 0.0246\n",
      "\n",
      "\n",
      "Resultados de Monte Carlo para Configuração 12 - 20% ruído (100 tentativas)\n",
      "Média do Índice Rand: 0.6343\n",
      "Desvio Padrão do Índice Rand: 0.0711\n",
      "\n",
      "\n",
      "Resultados de Monte Carlo para Configuração 12 - 30% ruído (100 tentativas)\n",
      "Média do Índice Rand: 0.5150\n",
      "Desvio Padrão do Índice Rand: 0.0231\n",
      "\n",
      "\n",
      "Resultados de Monte Carlo para Configuração 13 - 10% ruído (100 tentativas)\n",
      "Média do Índice Rand: 0.2731\n",
      "Desvio Padrão do Índice Rand: 0.0000\n",
      "\n",
      "\n",
      "Resultados de Monte Carlo para Configuração 13 - 20% ruído (100 tentativas)\n",
      "Média do Índice Rand: 0.2311\n",
      "Desvio Padrão do Índice Rand: 0.0005\n",
      "\n",
      "\n",
      "Resultados de Monte Carlo para Configuração 13 - 30% ruído (100 tentativas)\n",
      "Média do Índice Rand: 0.1913\n",
      "Desvio Padrão do Índice Rand: 0.0093\n"
     ]
    }
   ],
   "source": [
    "for nome_config, df in dfs_por_config.items():\n",
    "    labels = df[\"class\"].values\n",
    "    df.drop(\"class\", axis=1, inplace=True)\n",
    "    df.drop(\"classe_legenda\", axis=1, inplace=True)\n",
    "    dados = df.to_numpy()\n",
    "    num_clusters = 4\n",
    "    num_trials = 100\n",
    "    media_indice_rand, dp_indice_rand = simulacao_monte_carlo(dados, labels, num_clusters, num_trials)\n",
    "    print(\"\\n\")\n",
    "    print(f\"Resultados de Monte Carlo para {nome_config} ({num_trials} tentativas)\")\n",
    "    print(f\"Média do Índice Rand: {media_indice_rand:.4f}\")\n",
    "    print(f\"Desvio Padrão do Índice Rand: {dp_indice_rand:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Os centroides das três classes estão localizados próximos uns dos outros:\n",
    "$\\mu_1 = \\begin{bmatrix} 20 \\\\ 20 \\end{bmatrix},$\n",
    "$\\mu_2 = \\begin{bmatrix} 23 \\\\ 23 \\end{bmatrix},$\n",
    "$\\mu_3 = \\begin{bmatrix} 26 \\\\ 20 \\end{bmatrix}$\n",
    "\n",
    "As classes apresentam diferentes formas e orientações devido às suas matrizes de covariância:\n",
    "$\\Sigma_1 = \\begin{bmatrix} 10 & 9 \\\\ 9 & 10 \\end{bmatrix},$\n",
    "$\\Sigma_2 = \\begin{bmatrix} 10 & -9 \\\\ -9 & 10 \\end{bmatrix},$\n",
    "$\\Sigma_3 = \\begin{bmatrix} 12 & 0 \\\\ 0 & 1 \\end{bmatrix}$\n",
    "\n",
    "- $\\Sigma_1$ e $\\Sigma_2$ geram distribuições elípticas com inclinação forte nas diagonais principais e secundárias, respectivamente.\n",
    "- $\\Sigma_3$ resulta em uma distribuição fortemente alongada no eixo $x$.\n",
    "\n",
    "Cada classe possui $5\\%$ de outliers, gerados a partir dos mesmos centros e covariâncias, mas com deslocamentos adicionais direcionados para regiões distantes dos centros originais. Os deslocamentos aplicados foram:\n",
    "$\\Delta_1 = \\begin{bmatrix} -10 \\\\ 5 \\end{bmatrix},$\n",
    "$\\Delta_2 = \\begin{bmatrix} 10 \\\\ -10 \\end{bmatrix},$\n",
    "$\\Delta_3 = \\begin{bmatrix} 6 \\\\ 10 \\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def config1_outliers():\n",
    "    np.random.seed(42)\n",
    "    n = 150\n",
    "    frac_outlier = 0.05\n",
    "\n",
    "    # Covariâncias exageradas para formas mais elípticas e inclinadas\n",
    "    covs = [\n",
    "        [[10, 9], [9, 10]],     # fortemente inclinado (diagonal)\n",
    "        [[10, -9], [-9, 10]],   # diagonal oposta\n",
    "        [[12, 0], [0, 1]]       # fortemente alongado no eixo x\n",
    "    ]\n",
    "\n",
    "    mus = [[20, 20], [23, 23], [26, 20]]  # centroides próximos!\n",
    "    deslocamentos_outliers = [[-10, 5], [10, -10], [6, 10]]\n",
    "\n",
    "    dados, rotulos, outlier_flags = [], [], []\n",
    "\n",
    "    for i, (mu, cov, desloc) in enumerate(zip(mus, covs, deslocamentos_outliers)):\n",
    "        classe = np.random.multivariate_normal(mu, cov, size=n)\n",
    "        n_outliers = int(n * frac_outlier)\n",
    "\n",
    "        for j, ponto in enumerate(classe):\n",
    "            if j < n_outliers:\n",
    "                outlier = ponto + desloc + np.random.normal(0, 1.8, size=2)\n",
    "                dados.append(outlier)\n",
    "                outlier_flags.append(1)\n",
    "            else:\n",
    "                dados.append(ponto)\n",
    "                outlier_flags.append(0)\n",
    "            rotulos.append(f'Classe {i+1}')\n",
    "\n",
    "    # Garante que tudo fique no primeiro quadrante\n",
    "    dados = np.array(dados)\n",
    "    dados -= np.min(dados, axis=0)\n",
    "    dados += 1\n",
    "\n",
    "    df = pd.DataFrame(dados, columns=[\"x1\", \"x2\"])\n",
    "    df[\"Classe\"] = rotulos\n",
    "    df[\"Outlier\"] = outlier_flags\n",
    "    return df\n",
    "\n",
    "# 🔍 Visualização\n",
    "df = config1_outliers()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultados de Monte Carlo para dados com outliers (100 tentativas)\n",
      "Média do Índice Rand: 0.3229\n",
      "Desvio Padrão do Índice Rand: 0.0000\n"
     ]
    }
   ],
   "source": [
    "df.drop(\"Outlier\", axis=1, inplace=True)\n",
    "df['Classe'].replace({'Classe 1': 0, 'Classe 2': 1, 'Classe 3': 2}, inplace=True)\n",
    "labels = df[\"Classe\"].values\n",
    "df.drop(\"Classe\", axis=1, inplace=True)\n",
    "dados = df.to_numpy()\n",
    "num_clusters = 3\n",
    "num_trials = 100\n",
    "media_indice_rand, dp_indice_rand = simulacao_monte_carlo(dados, labels, num_clusters, num_trials)\n",
    "print(f\"Resultados de Monte Carlo para dados com outliers ({num_trials} tentativas)\")\n",
    "print(f\"Média do Índice Rand: {media_indice_rand:.4f}\")\n",
    "print(f\"Desvio Padrão do Índice Rand: {dp_indice_rand:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
