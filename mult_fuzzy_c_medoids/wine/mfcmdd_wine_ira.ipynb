{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Fuzzy C-medoids method: Implementation\n",
    "\n",
    "## Equations\n",
    "\n",
    "### $J= \\sum_{i=1}^{c} \\sum_{k=1}^{n} \\sum_{j=1}^{p} \\left(u_{ijk} \\right)^{m} d_{ijk}$ - Objective function to minimize.\n",
    "\n",
    "### $d_{ijk} = \\left(x_{jk} - y_{ij} \\right)^{2}$ - euclidian distance squared.\n",
    "\n",
    "### $q = \\argmin_{1 \\le i \\le c} \\sum_{j=1}^p \\sum_{k=1}^n (u_{ijk})^m \\cdot d_{ijk}$ - prototype coordinate of a given cluster in feature j.\n",
    "\n",
    "### $ u_{ijk} =  \\left[\\sum_{h=1}^{c}\\sum_{l=1}^{p} \\left(\\frac{d_{ijk}}{d_{hlk}}\\right)^{(1/(m-1))}  \\right]^{-1} $ - membership degree of pattern k in cluster $C_{i}$ on the feature j.\n",
    "\n",
    "### $\\delta_{ik} = \\sum_{j=1}^{p} u_{ijk}$ - represents an aggregation measure for all the p features.\n",
    "\n",
    "## Constraints:\n",
    "\n",
    "### - $u_{ijk} \\in [0, 1]$ for all i, j and k;\n",
    "### - $0 < \\sum_{j=1}^{p} \\sum_{k=1}^{n} u_{ijk} < n$ for all i and\n",
    "### - $\\sum_{i=1}^{c}\\sum_{j=1}^{p}u_{ijk} = 1$ for all k."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tratamento dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1728/3484265287.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df[\"Class\"].replace({1: 0, 2: 1, 3: 2}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/workspaces/Fuzzy_Clustering/datasets/wine.csv')\n",
    "df = df.rename(columns={'Wine': 'Class'})\n",
    "df[\"Class\"].replace({1: 0, 2: 1, 3: 2}, inplace=True)\n",
    "labels = df[\"Class\"].values\n",
    "df = df.drop(\"Class\", axis=1)\n",
    "#df = df[[\"Alcohol\", \"Malic.acid\", \"Proline\"]]\n",
    "dados = df.to_numpy()\n",
    "scaler = StandardScaler()\n",
    "dados = scaler.fit_transform(dados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic.acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Acl</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid.phenols</th>\n",
       "      <th>Proanth</th>\n",
       "      <th>Color.int</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Alcohol  Malic.acid   Ash   Acl   Mg  Phenols  Flavanoids  \\\n",
       "0    14.23        1.71  2.43  15.6  127     2.80        3.06   \n",
       "1    13.20        1.78  2.14  11.2  100     2.65        2.76   \n",
       "2    13.16        2.36  2.67  18.6  101     2.80        3.24   \n",
       "3    14.37        1.95  2.50  16.8  113     3.85        3.49   \n",
       "4    13.24        2.59  2.87  21.0  118     2.80        2.69   \n",
       "\n",
       "   Nonflavanoid.phenols  Proanth  Color.int   Hue    OD  Proline  \n",
       "0                  0.28     2.29       5.64  1.04  3.92     1065  \n",
       "1                  0.26     1.28       4.38  1.05  3.40     1050  \n",
       "2                  0.30     2.81       5.68  1.03  3.17     1185  \n",
       "3                  0.24     2.18       7.80  0.86  3.45     1480  \n",
       "4                  0.39     1.82       4.32  1.04  2.93      735  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Método de agrupamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MFCMedoids:\n",
    "    def __init__(self, c, X, m):\n",
    "        self.c = c\n",
    "        self.n = X.shape[0]\n",
    "        self.p = X.shape[1]\n",
    "        self.m = m\n",
    "        self.epsilon = 1e-10  # To prevent division by zero\n",
    "\n",
    "    def initialize_u(self):\n",
    "        return np.random.dirichlet(alpha=np.ones(self.c * self.p),\n",
    "                                   size=self.n).reshape(self.n, self.c, self.p)\n",
    "\n",
    "    def find_medoids(self, X, U):\n",
    "        medoids = np.zeros((self.c, self.p))\n",
    "        U_m = U ** self.m  # (n, c, p)\n",
    "\n",
    "        # Para cada possível q (0 <= q < n), criamos um tensor de distâncias quadradas para todos os outros k e p\n",
    "        # (n, n, p) -> distances_squared[k, q, j] = (X[k, j] - X[q, j]) ** 2\n",
    "        distances_squared = (X[:, np.newaxis, :] - X[np.newaxis, :, :]) ** 2  # shape (n, n, p)\n",
    "\n",
    "        for i in range(self.c):\n",
    "            # Para o cluster i, obtemos U_m[:, i, :] -> shape (n, p)\n",
    "            # Queremos calcular o custo de cada q ser o medoide: somatório sobre j e k de u_m[k, i, j] * d(k, q, j)\n",
    "            \n",
    "            # Expand u_m para fazer broadcast: (n, 1, p) para multiplicar com (n, n, p)\n",
    "            u_m_expanded = U_m[:, i, :][:, np.newaxis, :]  # shape (n, 1, p)\n",
    "\n",
    "            # Custo total para cada q: soma sobre k e j\n",
    "            cost_per_q = np.sum(u_m_expanded * distances_squared, axis=(0, 2))  # shape (n,)\n",
    "\n",
    "            best_q = np.argmin(cost_per_q)\n",
    "            medoids[i] = X[best_q]\n",
    "\n",
    "        return medoids\n",
    "\n",
    "\n",
    "    def get_distances(self, X, medoids):\n",
    "        return (X[:, np.newaxis, :] - medoids[np.newaxis, :, :]) ** 2\n",
    "\n",
    "    def update_u(self, D):\n",
    "        D = np.maximum(D, self.epsilon)  # Avoid division by zero\n",
    "        ratio = (D[:, np.newaxis, np.newaxis, :, :] / D[:, :, :, np.newaxis, np.newaxis]) ** (1 / (self.m - 1))\n",
    "        return 1 / np.sum(ratio, axis=(3, 4))\n",
    "\n",
    "    def get_objective_function(self, U, D):\n",
    "        return np.sum((U ** self.m) * D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mfcm_run(dados, num_clusters, m=2, max_iter=1000, epsilon=1e-5):\n",
    "    mfcm = MFCMedoids(c=num_clusters, X=dados, m=m)  # Create the MFCMedoids object\n",
    "\n",
    "    U = mfcm.initialize_u()  # Initialize the membership matrix\n",
    "\n",
    "    for _ in range(max_iter):\n",
    "        medoids = mfcm.find_medoids(dados, U)\n",
    "        D = mfcm.get_distances(dados, medoids)\n",
    "        new_U = mfcm.update_u(D)\n",
    "        \n",
    "        # Check for convergence\n",
    "        if np.linalg.norm(U - new_U) < epsilon:\n",
    "            break\n",
    "        \n",
    "        U = new_U\n",
    "\n",
    "    Delta = np.sum(U, axis=2)  # Summing over the second axis (variables j)\n",
    "\n",
    "    return medoids, U, Delta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulação de Monte Carlo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo_simulation(dados, labels, num_clusters, num_trials):\n",
    "    results = []\n",
    "    for _ in range(num_trials):\n",
    "        print(_)\n",
    "        medoids, U, Delta = mfcm_run(dados, num_clusters)\n",
    "        predicted_labels = np.argmax(Delta, axis=1)\n",
    "        ari = adjusted_rand_score(labels, predicted_labels)\n",
    "        if ari > 0.1:\n",
    "            results.append(ari)\n",
    "    mean_rand_index = np.mean(results)\n",
    "    std_rand_index = np.std(results)\n",
    "    return mean_rand_index, std_rand_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "Mean ARI: 0.532465560461492\n",
      "Std ARI: 0.007332538716867821\n"
     ]
    }
   ],
   "source": [
    "num_clusters = 3\n",
    "num_trials = 100\n",
    "mean_rand_index, std_rand_index = monte_carlo_simulation(dados, labels, num_clusters, num_trials)\n",
    "\n",
    "print(f\"Mean ARI: {mean_rand_index}\")\n",
    "print(f\"Std ARI: {std_rand_index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Medidas de Dispersão Bruta Totais ---\n",
      "  T (Dispersão Total): 21.0093\n",
      "  B (Dispersão Inter-grupo): 68.1315\n",
      "  J (Dispersão Intra-grupo): 102.9631\n",
      "\n",
      "--- 2. Medidas de Dispersão Bruta por Grupo (Ti, Bi, Ji) ---\n",
      "                Ti         Bi         Ji\n",
      "Grupo_1   4.752285  31.575440  40.613431\n",
      "Grupo_2   4.752285  31.575440  40.613431\n",
      "Grupo_3  11.504710   4.980588  21.736215\n",
      "\n",
      "--- 3. Medidas de Dispersão Bruta por Variável (Tj, Bj, Jj) ---\n",
      "              Tj         Bj         Jj\n",
      "Var_1   0.844514   1.518557   3.792876\n",
      "Var_2   3.534072  40.991133  47.394486\n",
      "Var_3   1.088429   0.782650   2.608194\n",
      "Var_4   2.039144   2.607298   7.578966\n",
      "Var_5   1.957301   1.463073   2.719978\n",
      "Var_6   1.275789   1.653342   5.345254\n",
      "Var_7   1.578708   1.996427   5.355111\n",
      "Var_8   2.642057  14.248410  17.016415\n",
      "Var_9   1.294687   0.340269   2.681241\n",
      "Var_10  1.498886   0.123192   1.146238\n",
      "Var_11  0.511399   0.371552   1.024250\n",
      "Var_12  1.779462   1.890318   4.572709\n",
      "Var_13  0.964832   0.145247   1.727360\n",
      "\n",
      "--- 4. Medida de Dispersão Bruta T_ij ---\n",
      "         Grupo_1   Grupo_2   Grupo_3\n",
      "Var_1   0.201866  0.201866  0.440783\n",
      "Var_2   0.512988  0.512988  2.508096\n",
      "Var_3   0.309732  0.309732  0.468964\n",
      "Var_4   0.466217  0.466217  1.106710\n",
      "Var_5   0.892907  0.892907  0.171488\n",
      "Var_6   0.231961  0.231961  0.811867\n",
      "Var_7   0.213459  0.213459  1.151790\n",
      "Var_8   0.268098  0.268098  2.105861\n",
      "Var_9   0.388438  0.388438  0.517812\n",
      "Var_10  0.631768  0.631768  0.235350\n",
      "Var_11  0.133177  0.133177  0.245044\n",
      "Var_12  0.068423  0.068423  1.642616\n",
      "Var_13  0.433252  0.433252  0.098328\n",
      "\n",
      "--- 5. Medida de Dispersão Bruta B_ij ---\n",
      "          Grupo_1    Grupo_2   Grupo_3\n",
      "Var_1    0.003812   0.003812  1.510932\n",
      "Var_2   20.494012  20.494012  0.003110\n",
      "Var_3    0.386866   0.386866  0.008919\n",
      "Var_4    1.226141   1.226141  0.155017\n",
      "Var_5    0.031316   0.031316  1.400441\n",
      "Var_6    0.036592   0.036592  1.580158\n",
      "Var_7    0.960940   0.960940  0.074547\n",
      "Var_8    7.124205   7.124205  0.000000\n",
      "Var_9    0.152419   0.152419  0.035431\n",
      "Var_10   0.019051   0.019051  0.085090\n",
      "Var_11   0.160879   0.160879  0.049793\n",
      "Var_12   0.935260   0.935260  0.019798\n",
      "Var_13   0.043948   0.043948  0.057351\n",
      "\n",
      "--- 6. Medida de Dispersão Bruta J_ij ---\n",
      "          Grupo_1    Grupo_2   Grupo_3\n",
      "Var_1    0.254563   0.254563  3.283750\n",
      "Var_2   22.355936  22.355936  2.682614\n",
      "Var_3    1.108809   1.108809  0.390575\n",
      "Var_4    2.777336   2.777336  2.024295\n",
      "Var_5    0.621847   0.621847  1.476284\n",
      "Var_6    0.432641   0.432641  4.479972\n",
      "Var_7    1.776656   1.776656  1.801798\n",
      "Var_8    7.455277   7.455277  2.105861\n",
      "Var_9    0.946088   0.946088  0.789066\n",
      "Var_10   0.454025   0.454025  0.238188\n",
      "Var_11   0.414944   0.414944  0.194362\n",
      "Var_12   1.277318   1.277318  2.018073\n",
      "Var_13   0.737991   0.737991  0.251377\n",
      "--- 7. Índices Globais ---\n",
      "  R (Heterogeneidade Global): 3.2429\n",
      "\n",
      "--- 8. Índices por Variável (CORj, CTRj) ---\n",
      "           COR(j)    CTR(j)\n",
      "Var_1    1.798142  0.022289\n",
      "Var_2   11.598840  0.601648\n",
      "Var_3    0.719064  0.011487\n",
      "Var_4    1.278624  0.038269\n",
      "Var_5    0.747495  0.021474\n",
      "Var_6    1.295937  0.024267\n",
      "Var_7    1.264596  0.029303\n",
      "Var_8    5.392923  0.209131\n",
      "Var_9    0.262820  0.004994\n",
      "Var_10   0.082189  0.001808\n",
      "Var_11   0.726540  0.005453\n",
      "Var_12   1.062297  0.027745\n",
      "Var_13   0.150541  0.002132\n",
      "\n",
      "--- 9. Índices de Contribuição Relativa por Grupo (T(i), B(i), J(i)) ---\n",
      "             T(i)      J(i)      B(i)\n",
      "Grupo_1  0.226199  0.394447  0.463449\n",
      "Grupo_2  0.226199  0.394447  0.463449\n",
      "Grupo_3  0.547601  0.211107  0.073103\n",
      "\n",
      "--- 10. Índice COR(i,j) ---\n",
      "         Grupo_1   Grupo_2   Grupo_3\n",
      "Var_1   0.004514  0.004514  1.789113\n",
      "Var_2   5.798980  5.798980  0.000880\n",
      "Var_3   0.355435  0.355435  0.008195\n",
      "Var_4   0.601302  0.601302  0.076021\n",
      "Var_5   0.016000  0.016000  0.715496\n",
      "Var_6   0.028682  0.028682  1.238573\n",
      "Var_7   0.608688  0.608688  0.047221\n",
      "Var_8   2.696461  2.696461  0.000000\n",
      "Var_9   0.117727  0.117727  0.027366\n",
      "Var_10  0.012710  0.012710  0.056769\n",
      "Var_11  0.314587  0.314587  0.097366\n",
      "Var_12  0.525586  0.525586  0.011126\n",
      "Var_13  0.045550  0.045550  0.059442\n",
      "\n",
      "--- 11. Índice CTR(i,j) ---\n",
      "         Grupo_1   Grupo_2   Grupo_3\n",
      "Var_1   0.000121  0.000121  0.303364\n",
      "Var_2   0.649049  0.649049  0.000624\n",
      "Var_3   0.012252  0.012252  0.001791\n",
      "Var_4   0.038832  0.038832  0.031124\n",
      "Var_5   0.000992  0.000992  0.281180\n",
      "Var_6   0.001159  0.001159  0.317263\n",
      "Var_7   0.030433  0.030433  0.014968\n",
      "Var_8   0.225625  0.225625  0.000000\n",
      "Var_9   0.004827  0.004827  0.007114\n",
      "Var_10  0.000603  0.000603  0.017084\n",
      "Var_11  0.005095  0.005095  0.009997\n",
      "Var_12  0.029620  0.029620  0.003975\n",
      "Var_13  0.001392  0.001392  0.011515\n",
      "\n",
      "--- 12. Índice CE(i,j) ---\n",
      "         Grupo_1   Grupo_2   Grupo_3\n",
      "Var_1   0.000056  0.000056  0.022177\n",
      "Var_2   0.300801  0.300801  0.000046\n",
      "Var_3   0.005678  0.005678  0.000131\n",
      "Var_4   0.017997  0.017997  0.002275\n",
      "Var_5   0.000460  0.000460  0.020555\n",
      "Var_6   0.000537  0.000537  0.023193\n",
      "Var_7   0.014104  0.014104  0.001094\n",
      "Var_8   0.104566  0.104566  0.000000\n",
      "Var_9   0.002237  0.002237  0.000520\n",
      "Var_10  0.000280  0.000280  0.001249\n",
      "Var_11  0.002361  0.002361  0.000731\n",
      "Var_12  0.013727  0.013727  0.000291\n",
      "Var_13  0.000645  0.000645  0.000842\n"
     ]
    }
   ],
   "source": [
    "def medoide_global_calc(dados, u_ijk, m=2):\n",
    "    n_objetos, p_variaveis = dados.shape\n",
    "    \n",
    "    u_ijk_m = u_ijk ** m # já eleva os graus de pertinência m\n",
    "    pesos_kj = np.sum(u_ijk_m, axis=0).T \n",
    "\n",
    "    min_dissimilarity = np.inf\n",
    "    medoid_index = -1\n",
    "\n",
    "    for q in range(n_objetos): # testa cada ponto como candidato a medoide\n",
    "        candidato_q = dados[q, :]\n",
    "        distancias_sq = (dados - candidato_q) ** 2 # distância dos pontos ao candidato\n",
    "        dissimilaridade_total_q = np.sum(pesos_kj * distancias_sq)\n",
    "        \n",
    "        if dissimilaridade_total_q < min_dissimilarity: # se o candidato for melhor\n",
    "            min_dissimilarity = dissimilaridade_total_q\n",
    "            medoid_index = q\n",
    "            \n",
    "    medoide_global = dados[medoid_index, :]\n",
    "    return medoide_global\n",
    "\n",
    "def indices(dados, prototipos, u_ijk, m=2):\n",
    "    n, p = dados.shape\n",
    "    c, _, _ = u_ijk.shape\n",
    "\n",
    "    u_ijk_m = u_ijk ** m\n",
    "    \n",
    "    grupo_nomes = [f'Grupo_{i+1}' for i in range(c)] # grupo1, grupo2, ... para output\n",
    "    variavel_nomes = [f'Var_{j+1}' for j in range(p)] # var1, var2, ... para output\n",
    "\n",
    "    z = medoide_global_calc(dados, u_ijk, m)\n",
    "\n",
    "    # dispersão intra-grupo (J)\n",
    "    dist_intra = (dados.T.reshape(1, p, n) - prototipos.reshape(c, p, 1)) ** 2\n",
    "    J_ijk = u_ijk_m * dist_intra\n",
    "    J = np.sum(J_ijk)\n",
    "    J_por_grupo = np.sum(J_ijk, axis=(1, 2)) # Ji\n",
    "    J_por_variavel = np.sum(J_ijk, axis=(0, 2)) # Jj\n",
    "    J_ij = np.sum(J_ijk, axis=2)               \n",
    "\n",
    "    # dispersão inter-grupo (B)\n",
    "    dist_inter = (prototipos - z) ** 2\n",
    "    B_ijk = u_ijk_m * dist_inter.reshape(c, p, 1)\n",
    "    B = np.sum(B_ijk)\n",
    "    B_por_variavel = np.sum(B_ijk, axis=(0, 2)) # Bj\n",
    "    B_por_grupo = np.sum(B_ijk, axis=(1, 2)) # Bi\n",
    "    B_ij = np.sum(B_ijk, axis=2)\n",
    "\n",
    "    # dispersão total (T)\n",
    "    dist_total = (dados - z) ** 2\n",
    "    dist_total_bcast = dist_total.T.reshape(1, p, n)\n",
    "    T_ijk = u_ijk_m * dist_total_bcast\n",
    "    T = np.sum(T_ijk)\n",
    "    T_por_variavel = np.sum(T_ijk, axis=(0, 2)) # Tj\n",
    "    T_por_grupo = np.sum(T_ijk, axis=(1, 2)) # Ti\n",
    "    T_ij = np.sum(T_ijk, axis=2)\n",
    "\n",
    "    # índices globais por variável\n",
    "    R_global = B / T\n",
    "    COR_j = np.divide(B_por_variavel, T_por_variavel, out=np.zeros_like(B_por_variavel), where=T_por_variavel!=0)\n",
    "    CTR_j = np.divide(B_por_variavel, B, out=np.zeros_like(B_por_variavel), where=B!=0)\n",
    "    df_indices_variavel = pd.DataFrame({'COR(j)': COR_j, 'CTR(j)': CTR_j}, index=variavel_nomes)\n",
    "\n",
    "    # índices de contribuição relativa por grupo\n",
    "    T_i_rel = np.divide(T_por_grupo, T, out=np.zeros_like(T_por_grupo), where=T!=0)\n",
    "    J_i_rel = np.divide(J_por_grupo, J, out=np.zeros_like(J_por_grupo), where=J!=0)\n",
    "    B_i_rel = np.divide(B_por_grupo, B, out=np.zeros_like(B_por_grupo), where=B!=0)\n",
    "    df_indices_grupo = pd.DataFrame({'T(i)': T_i_rel, 'J(i)': J_i_rel, 'B(i)': B_i_rel}, index=grupo_nomes)\n",
    "\n",
    "    # índices por grupo e variável\n",
    "    COR_ij = np.divide(B_ij, T_por_variavel, out=np.zeros_like(B_ij), where=T_por_variavel!=0)\n",
    "    df_cor_ij = pd.DataFrame(COR_ij.T, index=variavel_nomes, columns=grupo_nomes)\n",
    "    \n",
    "    CTR_ij = np.divide(B_ij, B_por_grupo.reshape(-1, 1), out=np.zeros_like(B_ij), where=B_por_grupo.reshape(-1, 1)!=0)\n",
    "    df_ctr_ij = pd.DataFrame(CTR_ij.T, index=variavel_nomes, columns=grupo_nomes)\n",
    "    \n",
    "    CE_ij = np.divide(B_ij, B, out=np.zeros_like(B_ij), where=B!=0)\n",
    "    df_ce_ij = pd.DataFrame(CE_ij.T, index=variavel_nomes, columns=grupo_nomes)\n",
    "\n",
    "    resultados = {\n",
    "        'T_total_bruto': T,\n",
    "        'B_total_bruto': B,\n",
    "        'J_total_bruto': J,\n",
    "        'dispersao_bruta_por_grupo': pd.DataFrame({'Ti': T_por_grupo, 'Bi': B_por_grupo, 'Ji': J_por_grupo}, index=grupo_nomes),\n",
    "        'dispersao_bruta_por_variavel': pd.DataFrame({'Tj': T_por_variavel, 'Bj': B_por_variavel, 'Jj': J_por_variavel}, index=variavel_nomes),\n",
    "        'T_ij_bruto': pd.DataFrame(T_ij.T, index=variavel_nomes, columns=grupo_nomes),\n",
    "        'B_ij_bruto': pd.DataFrame(B_ij.T, index=variavel_nomes, columns=grupo_nomes),\n",
    "        'J_ij_bruto': pd.DataFrame(J_ij.T, index=variavel_nomes, columns=grupo_nomes),\n",
    "        'R_global': R_global,\n",
    "        'indices_por_variavel': df_indices_variavel,\n",
    "        'indices_por_grupo': df_indices_grupo,\n",
    "        'COR(i,j)': df_cor_ij,\n",
    "        'CTR(i,j)': df_ctr_ij,\n",
    "        'CE(i,j)': df_ce_ij\n",
    "    }\n",
    "    \n",
    "    return resultados\n",
    "\n",
    "\n",
    "medoides_resultado, U_resultado, _ = mfcm_run(dados, num_clusters=3, m=2)\n",
    "u_ijk_para_analise = U_resultado.transpose(1, 2, 0)\n",
    "\n",
    "indices = indices(\n",
    "    dados=dados, \n",
    "    prototipos=medoides_resultado, \n",
    "    u_ijk=u_ijk_para_analise, \n",
    "    m=2\n",
    ")\n",
    "\n",
    "print(\"--- 1. Medidas de Dispersão Bruta Totais ---\")\n",
    "print(f\"  T (Dispersão Total): {indices['T_total_bruto']:.4f}\")\n",
    "print(f\"  B (Dispersão Inter-grupo): {indices['B_total_bruto']:.4f}\")\n",
    "print(f\"  J (Dispersão Intra-grupo): {indices['J_total_bruto']:.4f}\\n\")\n",
    "\n",
    "print(\"--- 2. Medidas de Dispersão Bruta por Grupo (Ti, Bi, Ji) ---\")\n",
    "print(indices['dispersao_bruta_por_grupo'])\n",
    "\n",
    "print(\"\\n--- 3. Medidas de Dispersão Bruta por Variável (Tj, Bj, Jj) ---\")\n",
    "print(indices['dispersao_bruta_por_variavel'])\n",
    "\n",
    "print(\"\\n--- 4. Medida de Dispersão Bruta T_ij ---\")\n",
    "print(indices['T_ij_bruto'])\n",
    "\n",
    "print(\"\\n--- 5. Medida de Dispersão Bruta B_ij ---\")\n",
    "print(indices['B_ij_bruto'])\n",
    "\n",
    "print(\"\\n--- 6. Medida de Dispersão Bruta J_ij ---\")\n",
    "print(indices['J_ij_bruto'])\n",
    "\n",
    "print(\"--- 7. Índices Globais ---\")\n",
    "print(f\"  R (Heterogeneidade Global): {indices['R_global']:.4f}\\n\")\n",
    "\n",
    "print(\"--- 8. Índices por Variável (CORj, CTRj) ---\")\n",
    "print(indices['indices_por_variavel'])\n",
    "\n",
    "print(\"\\n--- 9. Índices de Contribuição Relativa por Grupo (T(i), B(i), J(i)) ---\")\n",
    "print(indices['indices_por_grupo'])\n",
    "\n",
    "print(\"\\n--- 10. Índice COR(i,j) ---\")\n",
    "print(indices['COR(i,j)'])\n",
    "\n",
    "print(\"\\n--- 11. Índice CTR(i,j) ---\")\n",
    "print(indices['CTR(i,j)'])\n",
    "\n",
    "print(\"\\n--- 12. Índice CE(i,j) ---\")\n",
    "print(indices['CE(i,j)'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
